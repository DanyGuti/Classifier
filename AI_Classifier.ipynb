{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Basura con uso de Inteligencia Artificial\n",
    "\n",
    "El siguiente proceso, describe la metodología llevada a cabo para la realización de un modelo de IA, clasificador de imagenes, por categoría.\n",
    "\n",
    "En este caso, hay 9 categorías o mejor dicho 9 clases (hablando en términos de IA).\n",
    "\n",
    "Un modelo clasificatorio es un modelo de Inteligencia Artificial, dentro de la rama de entrenamiento supervisado.\n",
    "\n",
    "Un problema que nos habla acerca de clasificaciones, quiere decir que, por medio del correcto etiquetado de los datos, se puede llegar a la predicción de la pertenencia a una categoría dada una entrada de por medio.\n",
    "\n",
    "Un modelo de IA clasificatorio supervisado, debe ser entrenado con CNN (Convolutional Neural Networks).\n",
    "[PONER EXPLICACION DE PORQUE CNNs]\n",
    "\n",
    "Las clasificaciones del modelo son:\n",
    "* Vegetación\n",
    "* Basura de textil\n",
    "* Plástico\n",
    "* Papel\n",
    "* Basura miscelánea\n",
    "* Metal\n",
    "* Vidrio\n",
    "* Comida Orgánica\n",
    "* Cartón\n",
    "\n",
    "#### Metodología\n",
    "1. Recolección de datos (dataset) en: [https://archive.ics.uci.edu/dataset/908/realwaste]\n",
    "2. Verificación y validación de (dataset) de manera local\n",
    "3. Recolección de datos (dataset) en: [https://www.kaggle.com/datasets/alistairking/recyclable-and-household-waste-classification?resource=download] y [https://www.kaggle.com/datasets/alexanderuzhinskiy/moss-species-classification-dataset]\n",
    "4. Uso de scripts en shell para organización de imagenes por categorías ({clase}_{i}.jpg)\n",
    "5. Merge y separación de datos en batch de manera local\n",
    "6. Data splitting 70% training, 15% validation y 15% testing (se aplicó shuffle disminuyendo el bias por ciertas imágenes)\n",
    "7. Pre-procesado de datos (Siguiendo ideas de procesos de papers, ver sección abajo Ruido Gaussiano, Detección de border con Canny, étc)\n",
    "8. Data augmentation (balanceo de clases en disco)\n",
    "9. Data splitting, a nuevo directorio\n",
    "10. Feature engineering (feature extraction) con modelo pre-entrenado VGG16\n",
    "11. Construcción y entrenamiento del modelo con arquitectura CNN\n",
    "12. Muestra de gráficas (entrenamiento vs precisión de validación y entrenamiento vs pérdida de validación)\n",
    "13. Iteración del paso 11 en adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install pydot\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# 70% for training and 15% for testing and 15% for validation\n",
    "import os, shutil, pathlib\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "original_dir: Path = pathlib.Path.cwd()\n",
    "new_base_dir: Path = pathlib.Path.cwd() / 'trash_classifier'\n",
    "\n",
    "CATEGORIES: list[str] = ['Vegetation', 'Textile Trash', 'Plastic',\\\n",
    "                        'Paper', 'Miscellaneous Trash', 'Metal', 'Glass',\\\n",
    "                        'Food Organics', 'Cardboard'\n",
    "                        ]\n",
    "\n",
    "def get_length_of_category(path: Path) -> int:\n",
    "  '''Get the number of files in a category directory.\n",
    "  Args:\n",
    "      path (Path): Path to the category directory.\n",
    "  Returns:\n",
    "      int: Number of files in the category directory.\n",
    "  '''\n",
    "  return len([f for f in path.iterdir() if f.is_file() and f.suffix == '.jpg'])\n",
    "\n",
    "def get_all_catefory_files(path: Path) -> list[str]:\n",
    "  '''Get all files in a category directory sorted by name.\n",
    "  Args:\n",
    "      path (Path): Path to the category directory.\n",
    "  Returns:\n",
    "      list[str]: List of file names in the category directory.\n",
    "  '''\n",
    "  return sorted([f.name for f in path.iterdir() if f.is_file() and f.suffix == '.jpg'])\n",
    "\n",
    "def split_dataset(filenames: list[str], split_ratios: tuple[float, float, float]) -> tuple[\n",
    "                                                                  list[str], list[str], list[str]\n",
    "                                                              ]:\n",
    "  '''Split the dataset into training, testing, and validation sets.\n",
    "  Args:\n",
    "      filenames (list[str]): List of file names to split.\n",
    "      split_ratios (tuple[float, float, float]): Split ratios for training, testing, and validation sets.\n",
    "  Returns:\n",
    "      tuple[list[str], list[str], list[str]]: Tuple of lists containing training, testing, and validation file names.\n",
    "  '''\n",
    "  assert abs(sum(split_ratios)-1.0) < 1e-6, \"Split ratios must sum to 1\"\n",
    "  random.shuffle(filenames)\n",
    "  total = len(filenames)\n",
    "  train_end = int(split_ratios[0] * total)\n",
    "  test_end = int(train_end + (split_ratios[1] * total))\n",
    "  return filenames[:train_end], filenames[train_end:test_end], filenames[test_end:]\n",
    "\n",
    "def copy_files(src_dir: Path, dst_dir: Path, filenames: list[str], subset_name: str, category: str) -> None:\n",
    "  '''Copy files from source directory to destination directory.\n",
    "  Args:\n",
    "      src_dir (Path): Source directory containing the files.\n",
    "      dst_dir (Path): Destination directory to copy the files to.\n",
    "      filenames (list[str]): List of file names to copy.\n",
    "      subset_name (str): Name of the subset (train, test, val).\n",
    "      category (str): Category of the files.\n",
    "  Returns:\n",
    "      None\n",
    "  '''\n",
    "  dst_dir = dst_dir / subset_name / category\n",
    "  try:\n",
    "      os.makedirs(dst_dir)\n",
    "  except OSError:\n",
    "      raise OSError(f\"Directory {dst_dir} already exists.\")\n",
    "  for filename in filenames:\n",
    "    shutil.copyfile(src=src_dir / category / filename, dst=dst_dir / filename)\n",
    "        \n",
    "def prepare_subsets(base_dir: Path, target_dir: Path) -> None:\n",
    "  '''Prepare the subsets of the dataset by splitting and copying files.\n",
    "  Args:\n",
    "      base_dir (Path): Base directory containing the original dataset.\n",
    "      target_dir (Path): Target directory to copy the subsets to.\n",
    "  Returns:\n",
    "    None\n",
    "  '''\n",
    "  for category in CATEGORIES:\n",
    "    all_files = get_all_catefory_files(base_dir / category)\n",
    "    train_files, test_files, val_files = split_dataset(all_files, (0.7, 0.15, 0.15))\n",
    "    copy_files(base_dir, target_dir, train_files, 'train', category)\n",
    "    copy_files(base_dir, target_dir, test_files, 'test', category)\n",
    "    copy_files(base_dir, target_dir, val_files, 'val', category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting before pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetation: Train: 685, Test: 146, Val: 148\n",
      "Textile Trash: Train: 528, Test: 113, Val: 114\n",
      "Plastic: Train: 982, Test: 210, Val: 211\n",
      "Paper: Train: 765, Test: 164, Val: 165\n",
      "Miscellaneous Trash: Train: 375, Test: 80, Val: 81\n",
      "Metal: Train: 840, Test: 180, Val: 180\n",
      "Glass: Train: 644, Test: 138, Val: 139\n",
      "Food Organics: Train: 637, Test: 136, Val: 138\n",
      "Cardboard: Train: 604, Test: 129, Val: 131\n"
     ]
    }
   ],
   "source": [
    "prepare_subsets(original_dir, new_base_dir)\n",
    "# Check the number of files in each category\n",
    "for category in CATEGORIES:\n",
    "  train_count = get_length_of_category(new_base_dir / 'train' / category)\n",
    "  test_count = get_length_of_category(new_base_dir / 'test' / category)\n",
    "  val_count = get_length_of_category(new_base_dir / 'val' / category)\n",
    "  print(f\"{category}: Train: {train_count}, Test: {test_count}, Val: {val_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Se ha investigado arduamente en varios papers la mejor forma de detección de objetos, para su mejor reconocimiento.\n",
    "Entre las investigaciones, se ha encontrado la siguiente información importante, así como las técnicas de entrenamiento pertinentes.\n",
    "\n",
    "### Tipos de ruido [2]:\n",
    "* Ruido amplificador (Ruido Gaussiano)\n",
    "  * Forma idealizada del ruido blanco causado por fluctuaciones de señal. Puede haber más ruido en el canal azul que en el rojo y verde. \n",
    "* Ruido de impulsivo (Ruido de sal y pimienta)\n",
    "  * Cuando hay \"puntos\" que pueden ser \"pixeles muertos\" encontrados en la imagen.\n",
    "* Ruido de tiro\n",
    "  * Sigue distribución Poisson, no tan diferente a la Gaussiana. Se identifica cuando el ruido es causado por los puntos con mayor luz \"photon shot noise\" y en áreas oscuras \"dark shot noise\" o \"dark-current shot noise\".\n",
    "* Ruido de cuantización (ruido uniforme)\n",
    "  * Causado al cuanitificar los pixelexs de una imagen percibida hacia un número discreto de niveles.\n",
    "* Film grain\n",
    "  * El grano de una \"película\" fotográfica es una señal de ruido dependiente, relacionada con el ruido de tiro. \n",
    "* Ruido on-isotropico\n",
    "* Ruido de mancha (Ruido Multiplicativo)\n",
    "  * Ruido granular, que inherentemente existe dentro y degrada la calidad del radar activo y la apertura sintética de las de imágenes (SAR). Puede ser modelado con valores aleatorios multiplicados por cada valor de pixel, por eso el nombre. \n",
    "* Ruido periódico\n",
    "\n",
    "### Realce de contraste [2]\n",
    "Mejoramiento de la calidad de una imagen por medio de la equivalencia de histogramas. No se borran los detalles importantes. Incrementan la identificación del punto clave dentro de la imagen, mejorando la modificación de la imagen.\n",
    "Existen ADE, CLAHE y AHE.\n",
    "Con CLAHE, la imagen de entrada original es dividida en contextos de componentes no sobre-puestos llamados \"sub-imágenes\", celdas, o bloques utilizando el procedimiento CLAHE. Los dos parámetros de CLAHE que regulan la calidad de la imagen son bloques con tamaño y limitan el recorte. El histograma original es recortado, y se los pixeles recortados son redistribuidos en un nivel gris. La intensidad de cada pixel en la re-distribución del histograma está restricto a un máximo específico, no como el histograma estándar. El nivel de fuerza de los valores del pixel en la región del contexto del histograma es el pixel de salida con valor CLAHE. El histograma verdadero es dispersado hacia todas las intenisdades dentro del rango registrado de la iagen, cuando el histograma se concentra en los pixeles recortados en una altura en específico.[1]\n",
    "\n",
    "### Segmentación [2]\n",
    "Tarea de suma importancia para un problema de visión de computación, que consiste en particionar la imagen en múltiples segmentos o regiones basadas en ciertas características como su color, intensidad, textura o moción.\n",
    "La meta de la segmentación es simplificar la representación de la imagen al agrupar los pixeles y regiones que comparten propiedades similares, haciendo más eficiente y sencillo la extracción de \"features\" de una imagen (datos importantes\n",
    "de una imagen). Al aplicar esta técnica, se conseguirán regiones segmentadas que habilitan la eficiencia en el análisis e interpretación de los datos de una imagen. Puntos que pueden ser la iluminación de la imagen, en veces llamado bordes\n",
    "de la imagen. Técnica ampliamente utilizada para procesado de imagenes digitales, modelo de reconocimiento, morfología de imágenes, extracción de recursos. [1]\n",
    "\n",
    "---\n",
    "\n",
    "Algorithm to get the basic area of the image, it is also necessary to carry out image grayscale, histogram equalization, image filtering, size normalization. [4]\n",
    "\n",
    "---\n",
    "Proceso descrito de detección de objetos, con fines de cortar el objeto importante de una imagen [3]:\n",
    "1. Aplicación de Ruido Gausiano\n",
    "2. Aplicación de binarización de imagen\n",
    "3. Posicionamiento y selección\n",
    "4. Corte de imagen\n",
    "\n",
    "---\n",
    "### Referencias\n",
    "* [1] A. Demelash and E. Derb, “Habesha Cultural Cloth Classification Using Deep Learning,” Scientific Reports, vol. 15, no. 1, Apr. 2025, doi: https://doi.org/10.1038/s41598-025-98269-5.\n",
    "* [2] A. Hambal, Z. Pei, and F. Libent, “Image Noise Reduction and Filtering Techniques,” International Journal of Science and Research (IJSR) ISSN, vol. 6, no. 3, pp. 2319–7064, Mar. 2017, doi: https://doi.org/10.21275/25031706.he\n",
    "* [3] H. Wang, “Garbage Recognition and Classification System Based on Convolutional Neural Network VGG16,” 2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE), Apr. 2020, doi: https://doi.org/10.1109/aemcse50948.2020.00061. (IMAGE PRE-PROCESSING, OpenCV to crop objects)\n",
    "* [4] B. Gan and C. Zhang, “Research on the algorithm of urban waste classification and recycling based on deep learning technology,” Research on the algorithm of urban waste classification and recycling based on deep learning technology, Jul. 2020, doi: https://doi.org/10.1109/cvidl51233.2020.00-95.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "new_base_dir_pre_processed: Path = pathlib.Path.cwd() / 'trash_classifier_pre_processed'\n",
    "\n",
    "# Process the method from references of papers [1][3]\n",
    "class ImagePreprocessor:\n",
    "  '''\n",
    "  Class to preprocess images for object detection.\n",
    "  Attributes:\n",
    "      kernel_size (tuple[int, int]): Size of the kernel for Gaussian blur and morphological operations.\n",
    "      canny_thresh (tuple[int, int]): Thresholds for Canny edge detection.\n",
    "      itr (int): Number of iterations for morphological operations.\n",
    "  '''\n",
    "  def __init__(self, kernel_size: tuple[int, int] = (5, 5), canny_thresh: tuple[int, int]=(100,200), itr: int = 2) -> None:\n",
    "    self.kernel_size: tuple[int, int] = kernel_size\n",
    "    self.canny_thresh: tuple[int, int] = canny_thresh\n",
    "    self.itr: int = itr \n",
    "\n",
    "  # 1. Convert to grayscale all images\n",
    "  def convert_to_grayscale(self, image: cv2.Mat) -> cv2.Mat:\n",
    "    '''Convert the image to grayscale.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "    Returns:\n",
    "        cv2.Mat: Grayscale image.\n",
    "    '''\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # 2. Use Gaussian blur to reduce noise and detail in the image (default kernel size is 5x5) [1]\n",
    "  def gaussian_blur(self, image: cv2.Mat) -> cv2.Mat:\n",
    "    '''Apply Gaussian blur to the image.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "    Returns:\n",
    "        cv2.Mat: Gaussian blurred image.\n",
    "    '''\n",
    "    return cv2.GaussianBlur(image, self.kernel_size, 0)\n",
    "\n",
    "  # 3. Use Canny edge detection to detect edges in the image\n",
    "  def canny_edge_detection(self, image: cv2.Mat) -> cv2.Mat:\n",
    "    '''Apply Canny edge detection to the image.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "        Returns:\n",
    "        cv2.Mat: Canny edge detected image.\n",
    "    '''\n",
    "    return cv2.Canny(image, self.canny_thresh[0], self.canny_thresh[1])\n",
    "\n",
    "  # 4. Use dilation to increase the size of the edges\n",
    "  def dilate(self, image: cv2.Mat, kernel: cv2.Mat) -> cv2.Mat:\n",
    "    '''Apply dilation to the image.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "        kernel (cv2.Mat): Structuring element for dilation.\n",
    "    Returns:\n",
    "        cv2.Mat: Dilated image.\n",
    "    '''\n",
    "    return cv2.dilate(image, kernel, iterations=self.itr)\n",
    "\n",
    "  # 5. Use erosion to decrease the size of the edges\n",
    "  def erode(self, image: cv2.Mat, kernel: cv2.Mat) -> cv2.Mat:\n",
    "    '''Apply erosion to the image.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "        kernel (cv2.Mat): Structuring element for erosion.\n",
    "    Returns:\n",
    "        cv2.Mat: Eroded image.\n",
    "    '''\n",
    "    return cv2.erode(image, kernel, iterations=self.itr)\n",
    "\n",
    "  # 6. Use countours to find the edges in the image (binary image)\n",
    "  def find_contours(self, image: cv2.Mat) -> tuple[list[int, int]]:\n",
    "    '''Find contours in the image.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "    Returns:\n",
    "        tuple[list[int, int]]: List of contours found in the image.\n",
    "    '''\n",
    "    countours, _ = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return countours\n",
    "\n",
    "  # 7. Process the image sequentially\n",
    "  def process(self, image: cv2.Mat) -> np.ndarray:\n",
    "    '''Process the image using the defined methods.\n",
    "    Args:\n",
    "        image (cv2.Mat): Input image.\n",
    "    Returns:\n",
    "        np.ndarray: Processed image.\n",
    "    '''\n",
    "    grayscale_image: cv2.Mat = self.convert_to_grayscale(image)\n",
    "    blurred_image: cv2.Mat = self.gaussian_blur(grayscale_image)\n",
    "    edges: cv2.Mat = self.canny_edge_detection(blurred_image)\n",
    "    kernel: cv2.Mat = cv2.getStructuringElement(cv2.MORPH_RECT, self.kernel_size)\n",
    "    dilated_image: cv2.Mat = self.dilate(edges, kernel)\n",
    "    eroded_image: cv2.Mat = self.erode(dilated_image, kernel)\n",
    "    contours: list[tuple[int, int]] = self.find_contours(eroded_image)\n",
    "    if not contours:\n",
    "      return image\n",
    "    largest_contour: tuple[int, int] = max(contours, key=cv2.contourArea)\n",
    "    # Crop the image to the bounding box of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    highlighted_image: cv2.Mat = image.copy()\n",
    "    # Draw a rectangle around the largest contour\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    # Crop the image to the bounding box of the largest contour\n",
    "    # Resize the cropped image to a fixed size\n",
    "    resized_image: cv2.Mat = cv2.resize(highlighted_image, (224, 224))\n",
    "    # Convert the resized image to a numpy array\n",
    "    image_array: np.ndarray = np.array(resized_image)\n",
    "    \n",
    "    return image_array\n",
    "  \n",
    "PreprocessFunc = Callable[[cv2.Mat, ImagePreprocessor], np.ndarray]\n",
    "WrappedFunc = Callable[[list[str], ImagePreprocessor, str], None]\n",
    "\n",
    "# Wrapper to apply the function of processing the image from a not processed image\n",
    "# Apply the preprocessor to the image\n",
    "# Write the processed image to the output directory\n",
    "def apply_preprocessing(func: PreprocessFunc) -> WrappedFunc:\n",
    "  '''Decorator to apply preprocessing to a batch of image paths using a single-image function.\n",
    "  Args:\n",
    "      func (PreprocessFunc): Function to be decorated.\n",
    "  Returns:\n",
    "      wrapper (WrappedFunc): Decorated function.\n",
    "  '''\n",
    "  def wrapper(image_paths: list[str], preprocessor: ImagePreprocessor, output_dir: str) -> None:\n",
    "    '''Wrapper function to apply preprocessing to images.\n",
    "    Args:\n",
    "        image_paths (list[str]): List of image paths to process.\n",
    "        preprocessor (ImagePreprocessor): Preprocessor instance.\n",
    "        output_dir (str): Output directory to save processed images.\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    for image_path in image_paths:\n",
    "      image: cv2.Mat = cv2.imread(image_path)\n",
    "      # Apply the preprocessor to the image\n",
    "      if image is None:\n",
    "        print(f\"Error reading image {image_path}\")\n",
    "        continue\n",
    "      # Process the image using callback function from the decorator\n",
    "      processed_image: np.ndarray = func(image, preprocessor)\n",
    "      # Save the processed image\n",
    "      filename: Path = Path(image_path).name\n",
    "      output_path: Path = Path(output_dir) / filename\n",
    "      cv2.imwrite(str(output_path), processed_image)\n",
    "  return wrapper\n",
    "\n",
    "# 7. Instantiate the preprocessor\n",
    "preprocessor: ImagePreprocessor = ImagePreprocessor()\n",
    "\n",
    "# 8. Apply wrapper to the function as callable\n",
    "@apply_preprocessing\n",
    "def pre_process_images(image: cv2.Mat, preprocessor: ImagePreprocessor) -> np.ndarray:\n",
    "  '''Preprocess the image using the preprocessor.\n",
    "  Args:\n",
    "      image (cv2.Mat): Input image.\n",
    "      preprocessor (ImagePreprocessor): Preprocessor instance.\n",
    "  Returns:\n",
    "      np.ndarray: Processed image.\n",
    "  '''\n",
    "  return preprocessor.process(image)\n",
    "\n",
    "# 9. Apply the preprocessor to the images in the dataset\n",
    "def process_images_in_directory(input_dir: str, output_dir: str) -> None:\n",
    "  '''\n",
    "  Process images in the input directory and save them to the output directory.\n",
    "  Args:\n",
    "      input_dir (str): Input directory containing images.\n",
    "      output_dir (str): Output directory to save processed images.\n",
    "  Returns:\n",
    "    None\n",
    "  '''\n",
    "  # Look for all images \".jpg\" in the input directory\n",
    "  image_paths: list[str] = [str(p) for p in pathlib.Path(input_dir).rglob('*.jpg')]\n",
    "  # Apply the wrapper function to process the images\n",
    "  pre_process_images(image_paths, preprocessor, output_dir)\n",
    "\n",
    "# 10. Process the images in the dataset\n",
    "def process_dataset(input_dir: str, output_dir: str, label: str) -> None:\n",
    "  '''\n",
    "  Process the dataset by applying preprocessing to images in each category.\n",
    "  Args:\n",
    "      input_dir (str): Input directory containing the dataset.\n",
    "      output_dir (str): Output directory to save processed images.\n",
    "      label (str): Label for the dataset.\n",
    "  Returns:\n",
    "      None\n",
    "  '''\n",
    "  for category in CATEGORIES:\n",
    "    # Create the output directory if it doesn't exist\n",
    "    try:\n",
    "      os.makedirs(output_dir / label / category)\n",
    "    except OSError:\n",
    "      raise OSError(f\"Directory {output_dir / label / category} already exists.\")\n",
    "    # Process the images in the input directory\n",
    "    input_category_dir: Path = input_dir / label / category\n",
    "    print(f\"Processing {category} images from {input_category_dir}\")\n",
    "    output_category_dir: Path = output_dir / label / category\n",
    "    # Call the main processing function\n",
    "    process_images_in_directory(input_category_dir, output_category_dir)\n",
    "    print(f\"Processed {category} images from {input_category_dir} to {output_category_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n",
    "from pathlib import Path\n",
    "# 1. Create a ImageDataGenerator object\n",
    "datagen: ImageDataGenerator  = ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# 2. For label: train\n",
    "# 3. Get the greater index regex: \"category_{num}.jpg\" found in the directory\n",
    "def get_max_idx(path: Path) -> int:\n",
    "  '''Get the maximum index of the images in the directory.\n",
    "  Args:\n",
    "      path (Path): Path to the directory.\n",
    "  Returns:\n",
    "      int: Maximum index of the images in the directory.\n",
    "  '''\n",
    "  max_index: int = 0\n",
    "  for file in path.iterdir():\n",
    "    if file.is_file() and file.suffix == '.jpg':\n",
    "      filename: str = file.name\n",
    "      index: int = int(filename.split('_')[1].split('.')[0])\n",
    "      max_index = max(max_index, index)\n",
    "  return max_index\n",
    "\n",
    "# 4. For each category, augment the images on disk (writting the output image with name \"category_{num+1}.jpg\" to the same directory of reading)\n",
    "def process_data_augment_disk():\n",
    "  '''Process data augmentation on disk for each category.\n",
    "  Args:\n",
    "      None\n",
    "  Returns:\n",
    "      None\n",
    "  '''\n",
    "  for category in CATEGORIES:\n",
    "    # Get the path to the directory\n",
    "    input_dir: Path = new_base_dir_pre_processed / 'train' / category\n",
    "    output_dir: Path = new_base_dir_pre_processed / 'train' / category\n",
    "    # Get the maximum index of the images in the directory\n",
    "    max_index: int = get_max_idx(input_dir)\n",
    "    # Get the images in the directory\n",
    "    images: list[Path] = [f for f in input_dir.iterdir() if f.is_file() and f.suffix == '.jpg']\n",
    "    \n",
    "    # Grab randomly half of the images and augment them\n",
    "    # n + (num_augmeted * k) >= max_images\n",
    "    # num_augmented = ceil((max_images - n) / k)\n",
    "    if len(images) < 1000:\n",
    "      # Get the number of images to augment\n",
    "      num_images: int = int(np.ceil((1000 - len(images)) / 5))\n",
    "      # Get the images to augment\n",
    "      images: list[Path] = np.random.choice(images, size=num_images, replace=False)\n",
    "      # Generate the augmented images with the datagen\n",
    "      for image_path in images:\n",
    "        img = keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "        x = keras.preprocessing.image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        gen = datagen.flow(x, batch_size=1, save_prefix=category, save_format='jpg')\n",
    "        # Generate the augmented images\n",
    "        for _ in range(5):\n",
    "          next(gen)\n",
    "          # Save the augmented images\n",
    "          # Increment the index\n",
    "          max_index += 1\n",
    "          # Get the name of the image\n",
    "          filename: str = f\"{category}_{max_index}.jpg\"\n",
    "          # Save the image\n",
    "          keras.preprocessing.image.save_img(str(output_dir / filename), x[0])\n",
    "          print(f\"Saved {filename} to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n",
    "La siguiente casilla de código fue escrita con fines de hacer el split de la información (no correr, ya está ordenado el dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Create the new dataset pre-processed\n",
    "process_dataset(new_base_dir, new_base_dir_pre_processed, 'test')\n",
    "process_dataset(new_base_dir, new_base_dir_pre_processed, 'train')\n",
    "process_dataset(new_base_dir, new_base_dir_pre_processed, 'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data_augment_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetation: Train: 1000, Test: 146, Val: 148\n",
      "Textile Trash: Train: 1003, Test: 113, Val: 114\n",
      "Plastic: Train: 1002, Test: 210, Val: 211\n",
      "Paper: Train: 1000, Test: 164, Val: 165\n",
      "Miscellaneous Trash: Train: 1000, Test: 80, Val: 81\n",
      "Metal: Train: 1000, Test: 180, Val: 180\n",
      "Glass: Train: 1004, Test: 138, Val: 139\n",
      "Food Organics: Train: 1002, Test: 136, Val: 138\n",
      "Cardboard: Train: 1004, Test: 129, Val: 131\n"
     ]
    }
   ],
   "source": [
    "# Get the number of images in each category\n",
    "for category in CATEGORIES:\n",
    "  train_count = get_length_of_category(new_base_dir_pre_processed / 'train' / category)\n",
    "  test_count = get_length_of_category(new_base_dir_pre_processed / 'test' / category)\n",
    "  val_count = get_length_of_category(new_base_dir_pre_processed / 'val' / category)\n",
    "  print(f\"{category}: Train: {train_count}, Test: {test_count}, Val: {val_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Problemas con entrenamiento de datos con tamaño batch, la precisión de validación es menor.\n",
    "\n",
    "To attack the problem with batch :\n",
    "\n",
    "*Linearly increasing the learning rate with the batch size*\n",
    "\n",
    "Works empirically for ResNet-50 training. [1]\n",
    "Choose 0.1 as the initial learning rate for batch size 256, then when changing to a larger batch size b, we will increase the initial learning rate to 0.1 × b/256 [3]\n",
    "\n",
    "\n",
    "*No decaimiento de bias*\n",
    "\n",
    "En esta metodología, es aplicado este método. Como en algunos problemas de regularización, se suele utilizar la técnica de regularización L2 a todos los parámetros para que puedan llegar/acercarse a 0. Se recomienda aplicarlo únicamente a los pesos para evitar \"overfitting\". Solo se aplican a los pesos en capas convolucionales y totalemente conectadas. [1] [2]\n",
    "\n",
    "*Uso de batches más grandes*\n",
    "\n",
    "Se genera un decaimiento en la precisión del entrenamiento. [1]\n",
    "\n",
    "\n",
    "Referencias\n",
    "\n",
    "[1] F. Chollet, «Deep Learning with Python, Second Edition», O’Reilly Online Learning. https://learning.oreilly.com/library/view/deep-learning-with/9781617296864/Text/08.htm#heading_id_10\n",
    "\n",
    "[2] P. Goyal, P. Dollar, R. B. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He. Accurate, large minibatch SGD: training imagenet in 1 hour.\n",
    "CoRR, abs/1706.02677, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9015 files belonging to 9 classes.\n",
      "Found 1296 files belonging to 9 classes.\n",
      "Found 1307 files belonging to 9 classes.\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "curr_dir: Path = pathlib.Path.cwd()\n",
    "\n",
    "def get_size_directory(path: Path) -> int:\n",
    "  '''Get the size of the directory.\n",
    "  Args:\n",
    "      path (Path): Path to the directory.\n",
    "  Returns:\n",
    "      int: Size of the directory.'''\n",
    "  return len([f for f in path.iterdir() if f.is_file() and f.suffix == '.jpg'])\n",
    "\n",
    "def dataset_categories(base_dir: str) -> tf.data.Dataset:\n",
    "  '''Get the dataset from the directory.\n",
    "  Args:\n",
    "      base_dir (str): Base directory containing the dataset.\n",
    "  Returns:\n",
    "      tf.data.Dataset: Dataset object containing the images and labels.\n",
    "  '''\n",
    "  dataset: tf.data.Dataset = keras.utils.image_dataset_from_directory(\n",
    "    str(curr_dir / 'trash_classifier_pre_processed' / base_dir),\n",
    "    labels='inferred',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "  )\n",
    "  return dataset\n",
    "\n",
    "\n",
    "train_dataset: tf.data.Dataset = dataset_categories('train')\n",
    "\n",
    "test_dataset: tf.data.Dataset = dataset_categories('test')\n",
    "\n",
    "validation_dataset: tf.data.Dataset = dataset_categories('val')\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model architecture (VGG16)\n",
    "\n",
    "1. Uso de Modelo VG166 pre entrenado para realización de \"feature extraction\", ahorra tiempo y además nos da un buen acercamiento a los mejores parámetros a modificar \n",
    "\n",
    "2. Data Augmentation en el proceso, uso de primeros 4 bloques \"congelados\", haciendo un ajuste de parámetros \"fine-tuning\". Esto previene que una capa o conjunto de capas actualicen sus pesos mientras se entrena al modelo. Ya que capas Densas, al inicializarse de manera \"random\", realizan actualizaciones muy grandes, propagándose por la red, destruyendo lo aprendido anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# 1. Data augmentation constant\n",
    "data_augmentation = keras.Sequential([\n",
    "  keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  keras.layers.RandomRotation(0.1),\n",
    "  keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# 2. Create the base model VGG16 Scratch\n",
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.layers.Rescaling(1./255)(x)\n",
    "# First block\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='same')(x)\n",
    "# Second block\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='same')(x)\n",
    "# Third block\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='same')(x)\n",
    "# Fourth block\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='same')(x)\n",
    "# Fifth block\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D(pool_size=2, padding='same')(x)\n",
    "# Flatten the output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# Add the fully connected layers\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "# Add regularization (Dropout)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "# Add the output layer\n",
    "outputs = keras.layers.Dense(9, activation='softmax')(x)\n",
    "\n",
    "# 3. Create the model\n",
    "model: keras.Model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 4. Compile the model\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 5. Create callback to save the best model\n",
    "callbacks = [\n",
    "  keras.callbacks.ModelCheckpoint(\n",
    "    filepath=curr_dir / 'trash_classifier' / 'vgg16_scratch.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "  )\n",
    "]\n",
    "\n",
    "# 6. Train the model \n",
    "history = model.fit(\n",
    "  train_dataset,\n",
    "  epochs=10,\n",
    "  validation_data=validation_dataset,\n",
    "  callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 16:19:39.799254: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 16:24:09.763949: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 16:28:36.916923: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (9015, 7, 7, 512)\n",
      "Train labels shape: (9015,)\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction with VGG16\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# 1. Prepare the base VGG16 pre-trained model\n",
    "base_model: keras.applications.VGG16 = keras.applications.VGG16(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# 2. Produce feature extraction\n",
    "def get_features_and_labels(dataset: tf.data.Dataset) -> tuple[np.ndarray, np.ndarray]:\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = base_model.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "# Extract features and labels from the datasets\n",
    "train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "test_features, test_labels = get_features_and_labels(test_dataset)\n",
    "validation_features, validation_labels = get_features_and_labels(validation_dataset)\n",
    "\n",
    "np.save(curr_dir / 'trash_classifier_pre_processed' / 'train_features.npy', train_features)\n",
    "np.save(curr_dir / 'trash_classifier_pre_processed' / 'train_labels.npy', train_labels)\n",
    "\n",
    "np.save(curr_dir / 'trash_classifier_pre_processed' / 'test_features.npy', test_features)\n",
    "np.save(curr_dir / 'trash_classifier_pre_processed' / 'test_labels.npy', test_labels)\n",
    "\n",
    "np.save(curr_dir / 'trash_classifier_pre_processed' / 'validation_features.npy', validation_features)\n",
    "np.save(curr_dir / 'trash_classifier_pre_processed' / 'validation_labels.npy', validation_labels)\n",
    "\n",
    "# --- Print to verify\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features and labels from disk\n",
    "train_features = np.load(curr_dir / 'trash_classifier_pre_processed' / 'train_features.npy')\n",
    "train_labels = np.load(curr_dir / 'trash_classifier_pre_processed' / 'train_labels.npy')\n",
    "\n",
    "test_features = np.load(curr_dir / 'trash_classifier_pre_processed' / 'test_features.npy')\n",
    "train_labels = np.load(curr_dir / 'trash_classifier_pre_processed' / 'test_labels.npy')\n",
    "\n",
    "validation_features = np.load(curr_dir / 'trash_classifier_pre_processed' / 'validation_features.npy')\n",
    "validation_labels = np.load(curr_dir / 'trash_classifier_pre_processed' / 'validation_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9015, 7, 7, 512)\n",
      "(1296, 7, 7, 512)\n",
      "(1307, 7, 7, 512)\n",
      "(9015, 7, 7, 512)\n",
      "(9015,)\n"
     ]
    }
   ],
   "source": [
    "# Extract the pre-trained model features to make it the input of the classifier\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(validation_features.shape)\n",
    "\n",
    "#for i, (images, labels) in enumerate(train_dataset):\n",
    "#    print(f\"Batch {i}: images={images.shape}, labels={labels.shape}\")\n",
    "\n",
    "print(train_features.shape)  # should be (N, 7, 7, 512)\n",
    "print(train_labels.shape)    # should be (N,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo sin one-hot encoding (ronda 70 a 78%) de accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_10     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,441</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_10     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_21 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_22 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │        \u001b[38;5;34m18,441\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,079,305</span> (4.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,079,305\u001b[0m (4.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,074,185</span> (4.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,074,185\u001b[0m (4.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> (20.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,120\u001b[0m (20.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.3307 - loss: 17.2418 - val_accuracy: 0.7123 - val_loss: 13.0091\n",
      "Epoch 2/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - accuracy: 0.6230 - loss: 12.2992 - val_accuracy: 0.7567 - val_loss: 9.6167\n",
      "Epoch 3/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.6981 - loss: 9.1159 - val_accuracy: 0.7712 - val_loss: 7.2445\n",
      "Epoch 4/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.7128 - loss: 6.8998 - val_accuracy: 0.7819 - val_loss: 5.5794\n",
      "Epoch 5/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7262 - loss: 5.3905 - val_accuracy: 0.7865 - val_loss: 4.4212\n",
      "Epoch 6/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - accuracy: 0.7461 - loss: 4.2922 - val_accuracy: 0.7881 - val_loss: 3.6018\n",
      "Epoch 7/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.7616 - loss: 3.5050 - val_accuracy: 0.7980 - val_loss: 3.0150\n",
      "Epoch 8/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.7564 - loss: 2.9900 - val_accuracy: 0.8057 - val_loss: 2.5771\n",
      "Epoch 9/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.7705 - loss: 2.5467 - val_accuracy: 0.7888 - val_loss: 2.2652\n",
      "Epoch 10/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 84ms/step - accuracy: 0.7873 - loss: 2.1993 - val_accuracy: 0.8057 - val_loss: 1.9861\n",
      "Epoch 11/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.7861 - loss: 1.9665 - val_accuracy: 0.8187 - val_loss: 1.8042\n",
      "Epoch 12/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.8096 - loss: 1.7390 - val_accuracy: 0.8141 - val_loss: 1.6248\n",
      "Epoch 13/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.8089 - loss: 1.5766 - val_accuracy: 0.8095 - val_loss: 1.5121\n",
      "Epoch 14/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.8081 - loss: 1.4995 - val_accuracy: 0.8202 - val_loss: 1.4009\n",
      "Epoch 15/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 78ms/step - accuracy: 0.8262 - loss: 1.3497 - val_accuracy: 0.8148 - val_loss: 1.3350\n",
      "Epoch 16/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.8214 - loss: 1.2722 - val_accuracy: 0.8263 - val_loss: 1.2521\n",
      "Epoch 17/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.8200 - loss: 1.2097 - val_accuracy: 0.8202 - val_loss: 1.1870\n",
      "Epoch 18/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 75ms/step - accuracy: 0.8349 - loss: 1.1231 - val_accuracy: 0.8294 - val_loss: 1.1288\n",
      "Epoch 19/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.8352 - loss: 1.0887 - val_accuracy: 0.8301 - val_loss: 1.1015\n",
      "Epoch 20/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.8318 - loss: 1.0412 - val_accuracy: 0.8324 - val_loss: 1.0550\n",
      "Epoch 21/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.8394 - loss: 0.9948 - val_accuracy: 0.8309 - val_loss: 1.0119\n",
      "Epoch 22/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 61ms/step - accuracy: 0.8263 - loss: 1.0130 - val_accuracy: 0.8286 - val_loss: 1.0096\n",
      "Epoch 23/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.8414 - loss: 0.9586 - val_accuracy: 0.8309 - val_loss: 0.9773\n",
      "Epoch 24/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.8414 - loss: 0.9297 - val_accuracy: 0.8401 - val_loss: 0.9571\n",
      "Epoch 25/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8471 - loss: 0.9088 - val_accuracy: 0.8309 - val_loss: 0.9593\n",
      "Epoch 26/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.8372 - loss: 0.9164 - val_accuracy: 0.8416 - val_loss: 0.9540\n",
      "Epoch 27/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.8505 - loss: 0.8814 - val_accuracy: 0.8500 - val_loss: 0.9340\n",
      "Epoch 28/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.8459 - loss: 0.8793 - val_accuracy: 0.8340 - val_loss: 0.9078\n",
      "Epoch 29/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.8543 - loss: 0.8607 - val_accuracy: 0.8493 - val_loss: 0.8966\n",
      "Epoch 30/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 60ms/step - accuracy: 0.8509 - loss: 0.8535 - val_accuracy: 0.8416 - val_loss: 0.8965\n",
      "Epoch 31/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.8516 - loss: 0.8425 - val_accuracy: 0.8363 - val_loss: 0.8921\n",
      "Epoch 32/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8444 - loss: 0.8518 - val_accuracy: 0.8286 - val_loss: 0.9077\n",
      "Epoch 33/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.8474 - loss: 0.8395 - val_accuracy: 0.8256 - val_loss: 0.9179\n",
      "Epoch 34/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.8574 - loss: 0.8242 - val_accuracy: 0.8409 - val_loss: 0.8855\n",
      "Epoch 35/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.8532 - loss: 0.8190 - val_accuracy: 0.8340 - val_loss: 0.9053\n",
      "Epoch 36/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.8486 - loss: 0.8220 - val_accuracy: 0.8462 - val_loss: 0.8787\n",
      "Epoch 37/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 72ms/step - accuracy: 0.8645 - loss: 0.7962 - val_accuracy: 0.8347 - val_loss: 0.8600\n",
      "Epoch 38/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.8405 - loss: 0.8455 - val_accuracy: 0.8340 - val_loss: 0.8715\n",
      "Epoch 39/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8595 - loss: 0.8036 - val_accuracy: 0.8439 - val_loss: 0.8570\n",
      "Epoch 40/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.8547 - loss: 0.8078 - val_accuracy: 0.8401 - val_loss: 0.8775\n",
      "Epoch 41/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 54ms/step - accuracy: 0.8521 - loss: 0.8045 - val_accuracy: 0.8477 - val_loss: 0.8650\n",
      "Epoch 42/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.8549 - loss: 0.8025 - val_accuracy: 0.8424 - val_loss: 0.8507\n",
      "Epoch 43/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.8627 - loss: 0.7887 - val_accuracy: 0.8500 - val_loss: 0.8618\n",
      "Epoch 44/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.8741 - loss: 0.7729 - val_accuracy: 0.8454 - val_loss: 0.8521\n",
      "Epoch 45/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.8633 - loss: 0.7837 - val_accuracy: 0.8485 - val_loss: 0.8449\n",
      "Epoch 46/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.8481 - loss: 0.8111 - val_accuracy: 0.8493 - val_loss: 0.8484\n",
      "Epoch 47/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.8652 - loss: 0.7830 - val_accuracy: 0.8447 - val_loss: 0.8595\n",
      "Epoch 48/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.8538 - loss: 0.8129 - val_accuracy: 0.8432 - val_loss: 0.8535\n",
      "Epoch 49/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.8567 - loss: 0.8114 - val_accuracy: 0.8355 - val_loss: 0.8553\n",
      "Epoch 50/50\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.8625 - loss: 0.7870 - val_accuracy: 0.8493 - val_loss: 0.8601\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8637 - loss: 0.7711\n",
      "Test accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4 epochs=20\n",
    "# 512 => 0.83 accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4 epochs=50\n",
    "# 128 => 0.83 accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4 epochs=50\n",
    "# 1024 => 0.87 accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4 epochs=50\n",
    "# 2048 =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4 epochs=50\n",
    "# (1024, 512) =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4 epochs=50\n",
    "# (512, 128) =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.001) with RMSprop\n",
    "# 1024 =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.001) with Adam\n",
    "# 1024 =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-3\n",
    "# 1024 =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, regularized=0.002) with Adam, learning rate=1e-4\n",
    "# 512 =>  accuracy\n",
    "\n",
    "# Disk data augmentation (using global average pooling, and BatchNormalization, regularized=0.002) with Adam, learning rate=1e-4\n",
    "# 512 =>  accuracy\n",
    "\n",
    "# 1. Output of pre-trained model (feature extraction) from VGG16\n",
    "inputs = keras.Input(shape=(7, 7, 512))\n",
    "x = keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(2048,\n",
    "                      kernel_regularizer=keras.regularizers.l2(0.02))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(9, activation='softmax')(x)\n",
    "model_vgg16 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_vgg16.summary()\n",
    "# 2. Compile the model\n",
    "model_vgg16.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 3. Create callback to save the best model\n",
    "callbacks = [\n",
    "  keras.callbacks.ModelCheckpoint(\n",
    "    filepath=curr_dir / 'trash_classifier' / 'vgg16.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "  )\n",
    "]\n",
    "\n",
    "# 4. Train the model\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "  train_features,\n",
    "  train_labels,\n",
    "  epochs=50,\n",
    "  validation_data=(validation_features, validation_labels),\n",
    "  callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "loss, accuracy = model_vgg16.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    ")\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding\n",
    "\n",
    "Atacando posible problema de class labeling desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_encoded = keras.utils.to_categorical(train_labels, num_classes=9)\n",
    "test_labels_encoded = keras.utils.to_categorical(test_labels, num_classes=9)\n",
    "validation_labels_encoded = keras.utils.to_categorical(validation_labels, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# 1. Output of pre-trained model (feature extraction) from VGG16\n",
    "inputs = keras.Input(shape=(7, 7, 512))\n",
    "x = keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.Dense(256,\n",
    "                      kernel_regularizer=keras.regularizers.l2(0.002))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(64,\n",
    "                      kernel_regularizer=keras.regularizers.l2(0.002))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(9, activation='softmax')(x)\n",
    "model_vgg16 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_vgg16.summary()\n",
    "# 2. Compile the model\n",
    "model_vgg16.compile(\n",
    "  loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.3),\n",
    "  optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 3. Create callback to save the best model\n",
    "callbacks = [\n",
    "  keras.callbacks.ModelCheckpoint(\n",
    "    filepath=curr_dir / 'trash_classifier' / 'vgg16.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "  )\n",
    "]\n",
    "\n",
    "# 4. Train the model\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "  train_features,\n",
    "  train_labels_encoded,\n",
    "  epochs=50,\n",
    "  validation_data=(validation_features, validation_labels_encoded),\n",
    "  callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# 5. Evaluate the model\n",
    "loss, accuracy = model_vgg16.evaluate(\n",
    "    test_features,\n",
    "    test_labels_encoded,\n",
    ")\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Plot the graph of the model\n",
    "keras.utils.plot_model(\n",
    "    model_vgg16,\n",
    "    to_file=curr_dir / 'trash_classifier' / 'vgg16.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGxCAYAAADCo9TSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASzdJREFUeJzt3Xl4TGf/BvB7si+SkCCLrGorIqqWoiSpXSn1qr2NqlaL4q0WfVXFmtIiWlRXWiV4CS9VVZXE8lOqCIqmVEIQtWckkW3y/P44nZFJJslMMnNmkrk/1zXXzJzzzDnfHGFuz/OccxRCCAEiIiIimdiYuwAiIiKyLgwfREREJCuGDyIiIpIVwwcRERHJiuGDiIiIZMXwQURERLJi+CAiIiJZMXwQERGRrBg+iIiISFYMH1StKBQKvR5JSUlV2k90dDQUCkWlPpuUlGSUGizd6NGjERwcbBH7DQ4OxujRoyv8bFX+bA4fPozo6Gjcv3+/1LqIiAhEREQYvM2qSktLg0KhwNq1a2XfN1FV2Jm7ACJD/PLLL1rv582bh8TERCQkJGgtb968eZX2M3bsWPTu3btSn23Tpg1++eWXKtdA+tu2bRvc3d1Nuo/Dhw9jzpw5GD16NGrXrq21btWqVSbdN1FNw/BB1cpTTz2l9b5evXqwsbEptbyknJwcuLi46L0ff39/+Pv7V6pGd3f3Cush43riiSfMun8GTSLDcNiFapyIiAi0bNkSBw4cQKdOneDi4oIxY8YAADZt2oSePXvC19cXzs7OePzxxzFjxgxkZ2drbUPXsEtwcDD69euHH3/8EW3atIGzszOaNWuGr7/+Wqudrq790aNHo1atWrh48SL69u2LWrVqISAgAFOnTkVeXp7W569evYrBgwfDzc0NtWvXxsiRI3Hs2DG9utdv3bqF8ePHo3nz5qhVqxbq16+PZ555BgcPHtRqp+6u/+ijj7B06VKEhISgVq1a6NixI44cOVJqu2vXrkXTpk3h6OiIxx9/HN9++225dagNHDgQQUFBKCoqKrWuQ4cOaNOmjeb9ypUr0bVrV9SvXx+urq4IDQ3F4sWLUVBQUOF+dA27/PHHH+jduzdcXFxQt25dvP7663jw4EGpz+7duxcDBgyAv78/nJyc0KhRI4wbNw63b9/WtImOjsY777wDAAgJCSk1vKdr2OXu3bsYP348GjRoAAcHBzRs2BAzZ84s9eetUCgwceJErFu3Do8//jhcXFwQFhaG77//vsKfuyyHDh1Ct27d4ObmBhcXF3Tq1Am7du3SapOTk4O3334bISEhcHJygqenJ9q2bYu4uDhNm0uXLmHYsGHw8/ODo6MjvL290a1bNyQnJ1e6NiKAPR9UQ2VkZGDUqFGYNm0aFi5cCBsbKWdfuHABffv2xZQpU+Dq6oo//vgDixYtwq+//lpq6EaXU6dOYerUqZgxYwa8vb3x5Zdf4pVXXkGjRo3QtWvXcj9bUFCA5557Dq+88gqmTp2KAwcOYN68efDw8MD7778PAMjOzkZkZCTu3r2LRYsWoVGjRvjxxx8xdOhQvX7uu3fvAgBmz54NHx8fZGVlYdu2bYiIiMC+fftKfUGuXLkSzZo1Q2xsLABg1qxZ6Nu3L1JTU+Hh4QFACh4vv/wyBgwYgCVLliAzMxPR0dHIy8vTHNeyjBkzBgMGDEBCQgK6d++uWf7HH3/g119/xccff6xZ9tdff2HEiBEICQmBg4MDTp06hQULFuCPP/4oFfAq8vfffyM8PBz29vZYtWoVvL29sX79ekycOLFU27/++gsdO3bE2LFj4eHhgbS0NCxduhRPP/00zpw5A3t7e4wdOxZ3797FJ598gvj4ePj6+gIou8cjNzcXkZGR+OuvvzBnzhy0atUKBw8eRExMDJKTk0sFgV27duHYsWOYO3cuatWqhcWLF+P5559HSkoKGjZsaNDPvn//fvTo0QOtWrXCV199BUdHR6xatQr9+/dHXFyc5nfprbfewrp16zB//nw88cQTyM7Oxu+//447d+5ottW3b1+oVCosXrwYgYGBuH37Ng4fPqxz3guRQQRRNRYVFSVcXV21loWHhwsAYt++feV+tqioSBQUFIj9+/cLAOLUqVOadbNnzxYl/3oEBQUJJycncfnyZc2yhw8fCk9PTzFu3DjNssTERAFAJCYmatUJQGzevFlrm3379hVNmzbVvF+5cqUAIHbv3q3Vbty4cQKAWLNmTbk/U0mFhYWioKBAdOvWTTz//POa5ampqQKACA0NFYWFhZrlv/76qwAg4uLihBBCqFQq4efnJ9q0aSOKioo07dLS0oS9vb0ICgoqd/8FBQXC29tbjBgxQmv5tGnThIODg7h9+7bOz6lUKlFQUCC+/fZbYWtrK+7evatZFxUVVWq/QUFBIioqSvN++vTpQqFQiOTkZK12PXr0KPVnU5z6d+Ly5csCgPjf//6nWffhhx8KACI1NbXU58LDw0V4eLjm/erVq3X+eS9atEgAED/99JNmGQDh7e0tlEqlZtmNGzeEjY2NiImJ0VmnmvrPsfjvxVNPPSXq168vHjx4oFlWWFgoWrZsKfz9/TV/ji1bthQDBw4sc9u3b98WAERsbGy5NRBVBoddqEaqU6cOnnnmmVLLL126hBEjRsDHxwe2trawt7dHeHg4AOD8+fMVbrd169YIDAzUvHdyckKTJk1w+fLlCj+rUCjQv39/rWWtWrXS+uz+/fvh5uZWarLr8OHDK9y+2urVq9GmTRs4OTnBzs4O9vb22Ldvn86f79lnn4Wtra1WPQA0NaWkpOD69esYMWKE1jBUUFAQOnXqVGEtdnZ2GDVqFOLj45GZmQkAUKlUWLduHQYMGAAvLy9N25MnT+K5556Dl5eX5s/mpZdegkqlwp9//qn3zw8AiYmJaNGiBcLCwrSWjxgxolTbmzdv4vXXX0dAQIDmeAUFBQHQ73dCl4SEBLi6umLw4MFay9VDQ/v27dNaHhkZCTc3N817b29v1K9fX6/fq+Kys7Nx9OhRDB48GLVq1dIst7W1xYsvvoirV68iJSUFANC+fXvs3r0bM2bMQFJSEh4+fKi1LU9PTzz22GP48MMPsXTpUpw8eVLn8BlRZTB8UI2k7hYvLisrC126dMHRo0cxf/58JCUl4dixY4iPjweAUv/46lL8y1LN0dFRr8+6uLjAycmp1Gdzc3M17+/cuQNvb+9Sn9W1TJelS5fijTfeQIcOHbB161YcOXIEx44dQ+/evXXWWPLncXR0BPDoWKi74H18fEp9VtcyXcaMGYPc3Fxs3LgRALBnzx5kZGTg5Zdf1rS5cuUKunTpgmvXrmH58uU4ePAgjh07hpUrV2rVo687d+7oVXNRURF69uyJ+Ph4TJs2Dfv27cOvv/6qmfdi6H5L7r/kvKH69evDzs5Oa2gDqNrvVXH37t2DEELn77+fn5+mNgD4+OOPMX36dGzfvh2RkZHw9PTEwIEDceHCBQBSWN63bx969eqFxYsXo02bNqhXrx4mTZqkc+4MkSE454NqJF3X6EhISMD169eRlJSk6e0AYFHj115eXvj1119LLb9x44Zen//uu+8QERGBTz/9VGt5Zb8s1F+Kuvavb03NmzdH+/btsWbNGowbNw5r1qyBn58fevbsqWmzfft2ZGdnIz4+XtPrAKDSExu9vLz0qvn333/HqVOnsHbtWkRFRWmWX7x4sVL7Lb7/o0ePQgih9bt48+ZNFBYWom7dulXaflnq1KkDGxsbZGRklFp3/fp1ANDs29XVFXPmzMGcOXPw999/a3pB+vfvjz/++AOA1MP11VdfAQD+/PNPbN68GdHR0cjPz8fq1atN8jOQdWDPB1kN9ZeA+n/3ap999pk5ytEpPDwcDx48wO7du7WWq3sNKqJQKEr9fKdPny51fRR9NW3aFL6+voiLi4MQQrP88uXLOHz4sN7befnll3H06FEcOnQIO3fuRFRUlNZwj64/GyEEvvjii0rVHRkZibNnz+LUqVNayzds2KD13pDfiZK9QuXp1q0bsrKysH37dq3l6rOEunXrVuE2KsPV1RUdOnRAfHy8Vp1FRUX47rvv4O/vjyZNmpT6nLe3N0aPHo3hw4cjJSUFOTk5pdo0adIE7733HkJDQ3HixAmT1E/Wgz0fZDU6deqEOnXq4PXXX8fs2bNhb2+P9evXl/qCMqeoqCgsW7YMo0aNwvz589GoUSPs3r0be/bsAYAKzy7p168f5s2bh9mzZyM8PBwpKSmYO3cuQkJCUFhYaHA9NjY2mDdvHsaOHYvnn38er776Ku7fv4/o6Gi9h10Aac7KW2+9heHDhyMvL6/UabE9evSAg4MDhg8fjmnTpiE3Nxeffvop7t27Z3DNADBlyhR8/fXXePbZZzF//nzN2S7q/9GrNWvWDI899hhmzJgBIQQ8PT2xc+dO7N27t9Q2Q0NDAQDLly9HVFQU7O3t0bRpU625GmovvfQSVq5ciaioKKSlpSE0NBSHDh3CwoUL0bdvX60zf4wtJiYGPXr0QGRkJN5++204ODhg1apV+P333xEXF6cJXB06dEC/fv3QqlUr1KlTB+fPn8e6devQsWNHuLi44PTp05g4cSJeeOEFNG7cGA4ODkhISMDp06cxY8YMk9VP1oE9H2Q1vLy8sGvXLri4uGDUqFEYM2YMatWqhU2bNpm7NA1XV1ckJCQgIiIC06ZNw7/+9S9cuXJFcwXNklfWLGnmzJmYOnUqvvrqKzz77LP48ssvsXr1ajz99NOVrumVV17Bl19+iXPnzmHQoEGYO3cu/vOf/+ic0FsWDw8PPP/887h69So6d+5c6n/fzZo1w9atW3Hv3j0MGjQIb775Jlq3bq11Kq4hfHx8sH//fjRv3hxvvPEGRo0aBScnJ6xYsUKrnb29PXbu3IkmTZpg3LhxGD58OG7evImff/651DYjIiLw7rvvYufOnXj66afRrl07HD9+XOf+nZyckJiYiJEjR+LDDz9Enz59sHbtWrz99tuaOUamEh4erpnwOnr0aAwbNgyZmZnYsWOH1inbzzzzDHbs2IGXX34ZPXv2xOLFi/HSSy9h586dAKRj+Nhjj2HVqlUYPHgwBgwYgJ07d2LJkiWYO3euSX8GqvkUonhfKhFZpIULF+K9997DlStXKn3lVSIiS8FhFyILo/7febNmzVBQUICEhAR8/PHHGDVqFIMHEdUIDB9EFsbFxQXLli1DWloa8vLyEBgYiOnTp+O9994zd2lEREbBYRciIiKSFSecEhERkawYPoiIiEhWDB9EREQkK4ubcFpUVITr16/Dzc1N5yWyiYiIyPIIIfDgwQP4+flVeEFEiwsf169fR0BAgLnLICIiokpIT0+v8LIAFhc+1JcqTk9Ph7u7u5mrISIiIn0olUoEBATovOVASRYXPtRDLe7u7gwfRERE1Yw+UyY44ZSIiIhkxfBBREREsmL4ICIiIllZ3JwPIiIyLpVKhYKCAnOXQTWAra0t7OzsqnwpDIYPIqIaLCsrC1evXgVv40XG4uLiAl9fXzg4OFR6GwwfREQ1lEqlwtWrV+Hi4oJ69erxwo1UJUII5Ofn49atW0hNTUXjxo0rvJhYWQwOHwcOHMCHH36I48ePIyMjA9u2bcPAgQN1th03bhw+//xzLFu2DFOmTKlUgUREVDkFBQUQQqBevXpwdnY2dzlUAzg7O8Pe3h6XL19Gfn4+nJycKrUdgyNLdnY2wsLCsGLFinLbbd++HUePHoWfn1+lCiMiIuNgjwcZU2V7O4ozuOejT58+6NOnT7ltrl27hokTJ2LPnj149tlnK12cMalUwMGDQEYG4OsLdOkC2NqauyoiIiLrY/Q5H0VFRXjxxRfxzjvvoEWLFhW2z8vLQ15enua9Uqk0dkmIjwcmTwauXn20zN8fWL4cGDTI6LsjIiKichj9Oh+LFi2CnZ0dJk2apFf7mJgYeHh4aB7GvqlcfDwweLB28ACAa9ek5fHxRt0dEVGNo1IBSUlAXJz0rFKZuyLDRUREGDT3MC0tDQqFAsnJySarCQCSkpKgUChw//59k+7H0hg1fBw/fhzLly/H2rVr9R5jfPfdd5GZmal5pKenG60elUrq8dB1hpl62ZQp1fMvEhGRHOLjgeBgIDISGDFCeg4ONt1/3BQKRbmP0aNHV2q78fHxmDdvnt7tAwICkJGRgZYtW1Zqf1Q+ow67HDx4EDdv3kRgYKBmmUqlwtSpUxEbG4u0tLRSn3F0dISjo6MxyyhWT+kej+KEANLTpXYRESYpgYio2lL3HJf8D5y653jLFuMPXWdkZGheb9q0Ce+//z5SUlI0y0qetVNQUAB7e/sKt+vp6WlQHba2tvDx8THoM6Q/o/Z8vPjiizh9+jSSk5M1Dz8/P7zzzjvYs2ePMXell2K/w0ZpR0RkLczVc+zj46N5eHh4QKFQaN7n5uaidu3a2Lx5MyIiIuDk5ITvvvsOd+7cwfDhw+Hv7w8XFxeEhoYiLi5Oa7slh12Cg4OxcOFCjBkzBm5ubggMDMTnn3+uWV9y2EU9PLJv3z60bdsWLi4u6NSpk1YwAoD58+ejfv36cHNzw9ixYzFjxgy0bt3aoGOwdetWtGjRAo6OjggODsaSJUu01q9atQqNGzeGk5MTvL29MXjwYM26LVu2IDQ0FM7OzvDy8kL37t2RnZ1t0P7lYHD4yMrK0gQLAEhNTUVycjKuXLkCLy8vtGzZUuthb28PHx8fNG3a1Ni1V8jX17jtiIishSE9x3KbPn06Jk2ahPPnz6NXr17Izc3Fk08+ie+//x6///47XnvtNbz44os4evRoudtZsmQJ2rZti5MnT2L8+PF444038Mcff5T7mZkzZ2LJkiX47bffYGdnhzFjxmjWrV+/HgsWLMCiRYtw/PhxBAYG4tNPPzXoZzt+/DiGDBmCYcOG4cyZM4iOjsasWbOwdu1aAMBvv/2GSZMmYe7cuUhJScGPP/6Irl27ApB6jYYPH44xY8bg/PnzSEpKwqBBgyzz6rbCQImJiQJAqUdUVJTO9kFBQWLZsmV6bz8zM1MAEJmZmYaWVkphoRD+/kIoFEJIf1W0HwqFEAEBUjsioprm4cOH4ty5c+Lhw4cGf3bDBt3/bpZ8bNhggsL/sWbNGuHh4aF5n5qaKgCI2NjYCj/bt29fMXXqVM378PBwMXnyZM37oKAgMWrUKM37oqIiUb9+ffHpp59q7evkyZNCiEfffT///LPmM7t27RIANMe3Q4cOYsKECVp1dO7cWYSFhZVZp3q79+7dE0IIMWLECNGjRw+tNu+8845o3ry5EEKIrVu3Cnd3d6FUKktt6/jx4wKASEtLK3N/xlDW75Uh398G93xERERACFHqoU5lJaWlpZnt6qa2ttLptABQcv6r+n1sLK/3QURUkiX3HLdt21brvUqlwoIFC9CqVSt4eXmhVq1a+Omnn3DlypVyt9OqVSvNa/Xwzs2bN/X+jO8/P7z6MykpKWjfvr1W+5LvK3L+/Hl07txZa1nnzp1x4cIFqFQq9OjRA0FBQWjYsCFefPFFrF+/Hjk5OQCAsLAwdOvWDaGhoXjhhRfwxRdf4N69ewbtXy5GP9XW0gwaJE2KatBAe7m/v2kmSxER1QRdukj/TpZ14qJCAQQESO3k5urqqvV+yZIlWLZsGaZNm4aEhAQkJyejV69eyM/PL3c7JSeqKhQKFBUV6f0Z9VmdxT9T8kxPYeCQhxCi3G24ubnhxIkTiIuLg6+vL95//32EhYXh/v37sLW1xd69e7F79240b94cn3zyCZo2bYrU1FSDapBDjQ8fgBQw0tKAxERgwwbpOTWVwYOIqCzVqef44MGDGDBgAEaNGoWwsDA0bNgQFy5ckL2Opk2b4tdff9Va9ttvvxm0jebNm+PQoUNayw4fPowmTZrA9p+DbWdnh+7du2Px4sU4ffo00tLSkJCQAEAKP507d8acOXNw8uRJODg4YNu2bVX4qUzDau5qa2vL02mJiAyh7jnWdYXo2FjL+Q9co0aNsHXrVhw+fBh16tTB0qVLcePGDTz++OOy1vHmm2/i1VdfRdu2bdGpUyds2rQJp0+fRsOGDfXextSpU9GuXTvMmzcPQ4cOxS+//IIVK1Zg1apVAIDvv/8ely5dQteuXVGnTh388MMPKCoqQtOmTXH06FHs27cPPXv2RP369XH06FHcunVL9uOgD6sJH0REZLhBg4ABAyz73lizZs1CamoqevXqBRcXF7z22msYOHAgMjMzZa1j5MiRuHTpEt5++23k5uZiyJAhGD16dKnekPK0adMGmzdvxvvvv4958+bB19cXc+fO1VxcrXbt2oiPj0d0dDRyc3PRuHFjxMXFoUWLFjh//jwOHDiA2NhYKJVKBAUFYcmSJRXej80cFMLQASkTUyqV8PDwQGZmJtzd3c1dDhFRtZWbm4vU1FSEhIRU+tbnVDU9evSAj48P1q1bZ+5SjKas3ytDvr/Z80FERGQEOTk5WL16NXr16gVbW1vExcXh559/xt69e81dmsVh+CAiIjIChUKBH374AfPnz0deXh6aNm2KrVu3onv37uYuzeIwfBARERmBs7Mzfv75Z3OXUS1Yxam2REREZDkYPoiIiEhWDB9EREQkK4YPIiIikhXDBxEREcmK4YOIiIhkxfBBREQ1TkREBKZMmaJ5HxwcjNjY2HI/o1AosH379irv21jbKU90dDRat25t0n2YEsMHERFZjP79+5d5Ua5ffvkFCoUCJ06cMHi7x44dw2uvvVbV8rSUFQAyMjIs8n4qloThg4iILMYrr7yChIQEXL58udS6r7/+Gq1bt0abNm0M3m69evXg4uJijBIr5OPjA0dHR1n2VV0xfBARWQkhgOxs8zz0vYVpv379UL9+faxdu1ZreU5ODjZt2oRXXnkFd+7cwfDhw+Hv7w8XFxeEhoYiLi6u3O2WHHa5cOECunbtCicnJzRv3lzn/VemT5+OJk2awMXFBQ0bNsSsWbNQUFAAAFi7di3mzJmDU6dOQaFQQKFQaGouOexy5swZPPPMM3B2doaXlxdee+01ZGVladaPHj0aAwcOxEcffQRfX194eXlhwoQJmn3po6ioCHPnzoW/vz8cHR3RunVr/Pjjj5r1+fn5mDhxInx9feHk5ITg4GDExMRo1kdHRyMwMBCOjo7w8/PDpEmT9N53ZfDy6kREViInB6hVyzz7zsoCXF0rbmdnZ4eXXnoJa9euxfvvvw+FQgEA+O9//4v8/HyMHDkSOTk5ePLJJzF9+nS4u7tj165dePHFF9GwYUN06NChwn0UFRVh0KBBqFu3Lo4cOQKlUqk1P0TNzc0Na9euhZ+fH86cOYNXX30Vbm5umDZtGoYOHYrff/8dP/74o+aS6h4eHqW2kZOTg969e+Opp57CsWPHcPPmTYwdOxYTJ07UCliJiYnw9fVFYmIiLl68iKFDh6J169Z49dVXKz5oAJYvX44lS5bgs88+wxNPPIGvv/4azz33HM6ePYvGjRvj448/xo4dO7B582YEBgYiPT0d6enpAIAtW7Zg2bJl2LhxI1q0aIEbN27g1KlTeu230oSFyczMFABEZmamuUshIqrWHj58KM6dOycePnwohBAiK0sIqQ9C/kdWlv51nz9/XgAQCQkJmmVdu3YVw4cPL/Mzffv2FVOnTtW8Dw8PF5MnT9a8DwoKEsuWLRNCCLFnzx5ha2sr0tPTNet3794tAIht27aVuY/FixeLJ598UvN+9uzZIiwsrFS74tv5/PPPRZ06dURWsQOwa9cuYWNjI27cuCGEECIqKkoEBQWJwsJCTZsXXnhBDB06tMxaSu7bz89PLFiwQKtNu3btxPjx44UQQrz55pvimWeeEUVFRaW2tWTJEtGkSRORn59f5v6KK/l7pWbI9zd7PoiIrISLi9QDYa5966tZs2bo1KkTvv76a0RGRuKvv/7CwYMH8dNPPwEAVCoVPvjgA2zatAnXrl1DXl4e8vLy4KpP1wqA8+fPIzAwEP7+/pplHTt2LNVuy5YtiI2NxcWLF5GVlYXCwkK4u7vr/4P8s6+wsDCt2jp37oyioiKkpKTA29sbANCiRQvY2tpq2vj6+uLMmTN67UOpVOL69evo3Lmz1vLOnTtrejBGjx6NHj16oGnTpujduzf69euHnj17AgBeeOEFxMbGomHDhujduzf69u2L/v37w87OdBGBcz6IiKyEQiENfZjj8c/oid5eeeUVbN26FUqlEmvWrEFQUBC6desGAFiyZAmWLVuGadOmISEhAcnJyejVqxfy8/P12rbQMQFFUaLAI0eOYNiwYejTpw++//57nDx5EjNnztR7H8X3VXLbuvZpb29fal1RUZFB+yq5n+L7btOmDVJTUzFv3jw8fPgQQ4YMweDBgwEAAQEBSElJwcqVK+Hs7Izx48eja9euBs05MRTDBxERWZwhQ4bA1tYWGzZswDfffIOXX35Z80V68OBBDBgwAKNGjUJYWBgaNmyICxcu6L3t5s2b48qVK7h+/bpm2S+//KLV5v/+7/8QFBSEmTNnom3btmjcuHGpM3AcHBygUqkq3FdycjKys7O1tm1jY4MmTZroXXN53N3d4efnh0OHDmktP3z4MB5//HGtdkOHDsUXX3yBTZs2YevWrbh79y4AwNnZGc899xw+/vhjJCUl4ZdfftG756UyOOxCREQWp1atWhg6dCj+85//IDMzE6NHj9asa9SoEbZu3YrDhw+jTp06WLp0KW7cuKH1RVue7t27o2nTpnjppZewZMkSKJVKzJw5U6tNo0aNcOXKFWzcuBHt2rXDrl27sG3bNq02wcHBSE1NRXJyMvz9/eHm5lbqFNuRI0di9uzZiIqKQnR0NG7duoU333wTL774ombIxRjeeecdzJ49G4899hhat26NNWvWIDk5GevXrwcALFu2DL6+vmjdujVsbGzw3//+Fz4+PqhduzbWrl0LlUqFDh06wMXFBevWrYOzszOCgoKMVl9J7PkgIiKL9Morr+DevXvo3r07AgMDNctnzZqFNm3aoFevXoiIiICPjw8GDhyo93ZtbGywbds25OXloX379hg7diwWLFig1WbAgAH497//jYkTJ6J169Y4fPgwZs2apdXmX//6F3r37o3IyEjUq1dP5+m+Li4u2LNnD+7evYt27dph8ODB6NatG1asWGHYwajApEmTMHXqVEydOhWhoaH48ccfsWPHDjRu3BiAFOYWLVqEtm3bol27dkhLS8MPP/wAGxsb1K5dG1988QU6d+6MVq1aYd++fdi5cye8vLyMWmNxCqFr8MuMlEolPDw8kJmZafDEHiIieiQ3NxepqakICQmBk5OTucuhGqKs3ytDvr/Z80FERESyYvggIiIiWTF8EBERkawYPoiIiEhWDB9ERDWchZ1XQNWcMX6fGD6IiGoo9eW6Db0qJ1F5cnJyAJS+KqsheJExIqIays7ODi4uLrh16xbs7e1hY8P/b1LlCSGQk5ODmzdvonbt2lr3ojEUwwcRUQ2lUCjg6+uL1NTUUpcGJ6qs2rVrw8fHp0rbYPggIqrBHBwc0LhxYw69kFHY29tXqcdDjeGDiKiGs7Gx4RVOyaJwAJCIiIhkxfBBREREsmL4ICIiIlkxfBAREZGsDA4fBw4cQP/+/eHn5weFQoHt27dr1hUUFGD69OkIDQ2Fq6sr/Pz88NJLL+H69evGrJmIiIiqMYPDR3Z2NsLCwrBixYpS63JycnDixAnMmjULJ06cQHx8PP78808899xzRimWiIiIqj+FqMJF2hUKBbZt24aBAweW2ebYsWNo3749Ll++jMDAwAq3qVQq4eHhgczMTLi7u1e2NCIiIpKRId/fJr/OR2ZmJhQKBWrXrq1zfV5eHvLy8jTvlUqlqUsiIiIiMzLphNPc3FzMmDEDI0aMKDMFxcTEwMPDQ/MICAgwZUlERERkZiYLHwUFBRg2bBiKioqwatWqMtu9++67yMzM1DzS09NNVRIRERFZAJMMuxQUFGDIkCFITU1FQkJCuWM/jo6OcHR0NEUZREREZIGMHj7UwePChQtITEyEl5eXsXdBRERE1ZjB4SMrKwsXL17UvE9NTUVycjI8PT3h5+eHwYMH48SJE/j++++hUqlw48YNAICnpyccHByMVzkRERFVSwafapuUlITIyMhSy6OiohAdHY2QkBCdn0tMTERERESF2+eptkRERNWPSU+1jYiIQHl5pQqXDSEiIiIrwHu7EBERkawYPoiIiEhWVhM+8vOBQ4eAjRvNXQkREZF1M/nl1S1FVhbQpYv0+rnnABcX89ZDRERkraym58PTE1DfXiYtzZyVEBERWTerCR8A0LCh9PzXX+atg4iIyJpZZfi4dMm8dRAREVkzqwofjz0mPTN8EBERmY9VhQ8OuxAREZmfVYYP9nwQERGZj1WGj9RUoKjIvLUQERFZK6sKH4GBgK0tkJsL/HOzXSIiIpKZVYUPOzsgKEh6zXkfRERE5mFV4QPgvA8iIiJzY/ggIiIiWVld+OC1PoiIiMzL6sIHr/VBRERkXlYbPtjzQUREZB5WGz7+/hvIzjZvLURERNbI6sJH7dqAp6f0mr0fRERE8rO68AFw6IWIiMicGD6IiIhIVgwfREREJCurDB/qa33wdFsiIiL5WWX4YM8HERGR+Vh1+EhNBYqKzFsLERGRtbHK8BEQIN3hNj8fuH7d3NUQERFZF6sMH7a2QHCw9JrzPoiIiORlleED0D3vQ6UCkpKAuDjpWaUyR2VEREQ1m525CzCXkuEjPh6YPBm4evVRG39/YPlyYNAg+esjIiKqqay256P46bbx8cDgwdrBAwCuXZOWx8fLXx8REVFNZbXhQ93z8ddfUo+HEKXbqJdNmcIhGCIiImOx+vDx55+lezyKEwJITwcOHpSnLiIioprO6sPH/fv6tc/IMFkpREREVsVqw4e7O1C3rv7tfX1NVwsREZE1sdrwATzq/fDyAhQK3W0UCumiZF26yFcXERFRTcbwAaBfP+m5ZABRv4+NlS5MRkRERFXH8AHA1RXYsgVo0EB7vb+/tJzX+SAiIjIeq73IGKB9rY+VK4EBA6SzWjIypDkeXbqwx4OIiMjYrDp8lLzKqa0tEBFhtnKIiIisgsHDLgcOHED//v3h5+cHhUKB7du3a60XQiA6Ohp+fn5wdnZGREQEzp49a6x6jUodPtLSeBExIiIiuRgcPrKzsxEWFoYVK1boXL948WIsXboUK1aswLFjx+Dj44MePXrgwYMHVS7W2Bo0AOztgYIC6VLqREREZHoGD7v06dMHffr00blOCIHY2FjMnDkTg/6ZpfnNN9/A29sbGzZswLhx46pWrZHZ2gIhIdJVTv/6CwgMNHdFRERENZ9Rz3ZJTU3FjRs30LNnT80yR0dHhIeH4/Dhwzo/k5eXB6VSqfWQU8l5H0RERGRaRg0fN27cAAB4e3trLff29tasKykmJgYeHh6aR0BAgDFLqhDDBxERkbxMcp0PRYmrdQkhSi1Te/fdd5GZmal5pKenm6KkMhU/3ZaIiIhMz6in2vr4+ACQekB8i90M5ebNm6V6Q9QcHR3h6OhozDIMwp4PIiIieRm15yMkJAQ+Pj7Yu3evZll+fj7279+PTp06GXNXRsPwQUREJC+Dez6ysrJw8eJFzfvU1FQkJyfD09MTgYGBmDJlChYuXIjGjRujcePGWLhwIVxcXDBixAijFm4sISHS8507QGYm4OFh3nqIiIhqOoPDx2+//YbIyEjN+7feegsAEBUVhbVr12LatGl4+PAhxo8fj3v37qFDhw746aef4ObmZryqjcjNDahfH7h5U+r9eOIJc1dERERUsymEEMLcRRSnVCrh4eGBzMxMuLu7y7LPjh2BI0ekm8j961+y7JKIiKhGMeT726rvaqvGeR9ERETyYfgAwwcREZGcGD7Aa30QERHJieED7PkgIiKSE8MHHoWPy5eBwkLz1kJERFTTMXwA8PMDHB2l4CHz1d2JiIisDsMHABubRxcb49ALERGRaTF8/IPzPoiIiOTB8PEPhg8iIiJ5MHz8Qx0+eLotERGRaTF8/EN9rQ/2fBAREZkWw8c/OOxCREQkD4aPf6jPdrl3T3oQERGRaTB8/MPVFfDxkV6z94OIiMh0GD6K4dALERGR6TF8FMPwQUREZHoMH8XwdFsiIiLTY/gohqfbEhERmR7DRzEcdiEiIjI9ho9i1OHjyhWgoMC8tRAREdVUDB/F+PgATk6ASiUFECIiIjI+ho9ibGwe9X5cuGDeWoiIiGoqho8SWraUnn//3bx1EBER1VQMHyW0aiU9nz5t3jqIiIhqKoaPEhg+iIiITIvhowR1+Dh3jme8EBERmQLDRwmBgYC7uxQ8UlLMXQ0REVHNw/BRgkLBoRciIiJTYvjQITRUemb4ICIiMj6GDx3Y80FERGQ6DB86MHwQERGZDsOHDuoLjV27Bty5Y95aiIiIahqGDx3c3YGQEOn1mTPmrYWIiKimYfgoA4deiIiITIPhowwMH0RERKbB8FEGhg8iIiLTYPgogzp8/P47oFKZtxYiIqKahOGjDI89Bjg7Aw8fAn/9Ze5qiIiIag6GjzLY2j465ZZDL0RERMbD8FEOXfM+VCogKQmIi5OeOSRDRERkGKOHj8LCQrz33nsICQmBs7MzGjZsiLlz56KoqMjYuzK5kuEjPh4IDgYiI4ERI6Tn4GBpOREREenHztgbXLRoEVavXo1vvvkGLVq0wG+//YaXX34ZHh4emDx5srF3Z1LFw0d8PDB4MCCEdptr16TlW7YAgwbJXyMREVF1oxCi5Ndp1fTr1w/e3t746quvNMv+9a9/wcXFBevWravw80qlEh4eHsjMzIS7u7sxSzPYnTtA3brSaz8/4Pp13e0UCsDfH0hNleaKEBERWRtDvr+NPuzy9NNPY9++ffjzzz8BAKdOncKhQ4fQt29fne3z8vKgVCq1HpbCywto0EB6XVbwAKTekPR04OBBeeoiIiKqzow+7DJ9+nRkZmaiWbNmsLW1hUqlwoIFCzB8+HCd7WNiYjBnzhxjl2E0rVpJQyv6yMgwbS1EREQ1gdF7PjZt2oTvvvsOGzZswIkTJ/DNN9/go48+wjfffKOz/bvvvovMzEzNIz093dglVYl63oc+fH1NVwcREVFNYfSej3feeQczZszAsGHDAAChoaG4fPkyYmJiEBUVVaq9o6MjHB0djV2G0ajDh4MDUFBQesIp8GjOR5cu8tZGRERUHRm95yMnJwc2NtqbtbW1rZan2gKPwoednRQ8FArt9er3sbGcbEpERKQPo4eP/v37Y8GCBdi1axfS0tKwbds2LF26FM8//7yxdyWLpk0Be3sgJwf49NNHE1DV/P15mi0REZEhjD7s8sknn2DWrFkYP348bt68CT8/P4wbNw7vv/++sXclC3t7oHlz4NQpKXikpUlntWRkSHM8unRhjwcREZEhjH6dj6qypOt8qL30ErBuHTB/PjBzprmrISIisjxmvc5HTRQaKj3zBnNERERVx/ChB103mCMiIqLKYfjQgzp8/Pkn8PCheWshIiKq7hg+9ODjI93jpagIOHfO3NUQERFVbwwfelAoOPRCRERkLAwfemL4ICIiMg6GDz0xfBARERkHw4ee1OHj1Cnd93chIiIi/TB86Kl5c8DGBrhzB7hxw9zVEBERVV8MH3pydgaaNJFec+iFiIio8hg+DMB5H0RERFXH8GEAhg8iIqKqY/gwAMMHERFR1TF8GEAdPs6fB/LzzVsLERFRdcXwYYDAQMDdHSgoAFJSzF0NERFR9cTwYQBeZp2IiKjqGD4MxPBBRERUNQwfBmL4ICIiqhqGDwMxfBAREVUNw4eBWraUnq9fB27fNm8tRERE1RHDh4Hc3ICGDaXXZ86YtxYiIqLqiOGjEtRDL8nJZi2DiIioWmL4qIQOHaTngwfNWwcREVF1xPBRCeHh0vOBA0BRkXlrISIiqm4YPiqhbVvAxQW4cwc4e9bc1RAREVUvDB+VYG8PPP209DopyaylEBERVTsMH5WkHnrZv9+8dRAREVU3DB+VFBEhPe/fz3kfREREhmD4qCT1vI/bt4Fz58xdDRERUfXB8FFJDg5Ap07Saw69EBER6Y/howrUQy+cdEpERKQ/ho8qKD7vQwizlkJERFRt2Jm7gOqsXTvA2Rm4dQs4fx5o3vzROpVKugJqRgbg6wt06QLY2pqvViIiIkvBno8qKD7vo/jQS3w8EBwMREYCI0ZIz8HB0nIiIiJrx/BRRSXnfcTHA4MHA1evare7dk1azgBCRETWjuGjiopfbKywEJg8Wff8D/WyKVOkIRkiIiJrxfBRRe3bA05OwM2bwPr1pXs8ihMCSE/n3XCJiMi6MXxUkaOj4df7yMgwXT1ERESWjuHDCNRDL2lp+rX39TVZKURERBaP4cMI1JNOz50DGjQAFArd7RQKICBAOu2WiIjIWpkkfFy7dg2jRo2Cl5cXXFxc0Lp1axw/ftwUu7II6nkff/8NTJsmLSsZQNTvY2N5vQ8iIrJuRg8f9+7dQ+fOnWFvb4/du3fj3LlzWLJkCWrXrm3sXVkMJyfgqaek146OwJYtUg9Icf7+0vJBg+Svj4iIyJIY/QqnixYtQkBAANasWaNZFhwcbOzdWJyICOlaH0lJQFwcMGAAr3BKRESki9F7Pnbs2IG2bdvihRdeQP369fHEE0/giy++KLN9Xl4elEql1qM6KnmfF1tbadnw4dIzgwcREZHE6OHj0qVL+PTTT9G4cWPs2bMHr7/+OiZNmoRvv/1WZ/uYmBh4eHhoHgEBAcYuSRYdOkhDLhkZwIUL5q6GiIjIcimEMO79WB0cHNC2bVscPnxYs2zSpEk4duwYfvnll1Lt8/LykJeXp3mvVCoREBCAzMxMuLu7G7M0k4uIkHo+PvsMeO01c1dDREQkH6VSCQ8PD72+v43e8+Hr64vmxW/vCuDxxx/HlStXdLZ3dHSEu7u71qO6Kj70QkRERLoZPXx07twZKSkpWsv+/PNPBAUFGXtXFkd9sbGkJN33dyEiIiIThI9///vfOHLkCBYuXIiLFy9iw4YN+PzzzzFhwgRj78riPPUU4OAAXL8OXLxo7mqIiIgsk9HDR7t27bBt2zbExcWhZcuWmDdvHmJjYzFy5Ehj78riODs/ut4Hh16IiIh0M/p1PgCgX79+6Nevnyk2bfHCw4EDB6Shl7FjzV0NERGR5eG9XYxMPemU8z6IiIh0Y/gwMvW8j2vXgEuXzF0NERGR5WH4MDIXF+lGc4DU+0FERETaGD5MoPjQCxEREWlj+DCBkvd5ISIiokcYPkygY0fA3h5ITwdSU81dDRERkWVh+DABzvsgIiIqG8OHiaiHXvbtM2sZREREFofhw0T69pWed+4EcnPNWwsREZElYfgwkaeeAvz9gQcPgD17zF0NERGR5WD4MBEbG+CFF6TXmzebtxYiIiJLwvBhQkOHSs87dgAPH5q3FiIiIkvB8GFC7dsDQUFAVhawe7e5qyEiIrIMDB8mpFAAQ4ZIrzdtKr1epZJOxY2Lk55VKjmrIyIiMg+GDxNTh4/vvweysx8tj48HgoOByEhgxAjpOThYWk5ERFSTMXyY2JNPAg0bAjk5wK5d0rL4eGDwYODqVe22165JyxlAiIioJmP4MLHiQy+bN0tDK5Mn677ni3rZlCkcgiEiopqL4UMG6vCxaxfw00+lezyKE0K6J8zBg/LURkREJDeGDxm0bg00bixd6fSHH/T7TEaGSUsiIiIyG4YPGRQfeklO1u8zvr4mK4eIiMisGD5kor7g2LFjgJ+fFEh0USiAgACgSxf5aiMiIpITw4dMWrYEmjUD8vKkM1qA0gFE/T42FrC1lbU8IiIi2TB8yKT40MulS8CWLUCDBtpt/P2l5YMGyV8fERGRXBRC6Drp03yUSiU8PDyQmZkJd3d3c5djVGfPSj0g9vbAzZuAm5t0VktGhjTHo0sX9ngQEVH1ZMj3t51MNRGAFi2kx9mzwPbtwOjRQESEmYsiIiKSGYddZKaeeLp5s3nrICIiMheGD5mp533s3QvcvWveWoiIiMyB4UNmTZsCYWFAYSGwbZu5qyEiIpIfw4cZFL/XCxERkbVh+DADdfjYtw+4dcu8tRAREcmN4cMMGjUC2rSR7lzLoRciIrI2DB9mou792LTJvHUQERHJjeHDTNThIykJ+Ptvs5ZCREQkK4YPMwkJAdq1A4qKgPh4c1dDREQkH4YPM1JfcCwuzrx1EBERyYnhw4yGDpXu5XLwIHDypLmrISIikgfDhxn5+z/q/ViyxLy1EBERyYXhw8ymTpWeN24Erlwxby1ERERyYPgwszZtgGeeka75sXx56fUqlXRGTFyc9KxSyV0hERGRcTF8WIB33pGeP/8cuH//0fL4eCA4GIiMBEaMkJ6Dg3l2DBERVW8mDx8xMTFQKBSYMmWKqXdVbfXqBbRsCWRlSQEEkALG4MHA1avaba9dk5YzgBARUXVl0vBx7NgxfP7552jVqpUpd1PtKRSP5n4sXw48fAhMngwIUbqtetmUKRyCISKi6slk4SMrKwsjR47EF198gTp16phqNzXGiBGAnx9w/Towd27pHo/ihADS06VTdImIiKobk4WPCRMm4Nlnn0X37t3LbZeXlwelUqn1sEYODsCkSdLr9ev1+0xGhunqISIiMhWThI+NGzfixIkTiImJqbBtTEwMPDw8NI+AgABTlFQtjBsH1Kol9Wrow9fXtPUQERGZgtHDR3p6OiZPnozvvvsOTk5OFbZ/9913kZmZqXmk6/vNWwPVrg28+qr02tFRmguii0IBBAQAXbrIVhoREZHRKITQNa2x8rZv347nn38etra2mmUqlQoKhQI2NjbIy8vTWleSUqmEh4cHMjMz4e7ubszSqoXLl4HHHns0mVSh0J54qg4kW7YAgwbJXx8REZEuhnx/G73no1u3bjhz5gySk5M1j7Zt22LkyJFITk4uN3gQEBQEDBkive7aFWjQQHu9vz+DBxERVW92xt6gm5sbWrZsqbXM1dUVXl5epZaTbm+/LV3R9P/+D7h4EUhLkyaX+vpKQy3Mb0REVJ0ZPXxQ1akvuZ6QAHzyCW86R0RENYvR53xUlbXP+VDbvRvo2/fR2S+1a5u7IiIiorKZdc4HGUfv3o8uuf7FF+auhoiIyHgYPixUyUuu5+ebtx4iIiJjYfiwYMOHS5NMr10DNm40dzVERETGwfBhwRwdpRvMAcBHHwFFReath4iIyBgYPizcuHGAmxtw5gywerXuNioVkJQknZ6blMS73RIRkWVj+LBwtWsDCxdKr6dPL33fl/h4IDgYiIyU7owbGSm9j4+XuVAiIiI9MXxUA+PHAx07Sme+jB//6HLr8fHA4MHA1ava7a9dk5YzgBARkSVi+KgGbGyAL78EHByA778HNm2ShlYmT9a+74uaetmUKRyCISIiy8PwUU00bw7MnCm9njRJCiElezyKE0Iaojl4UJ76iIiI9MXwUY3MmAG0aAHcuqX/JdczMkxbExERkaEYPqoRBwdp+EWh0L9Hw9fXtDUREREZiuGjmnnqKeDNN6XX5d3dVqEAAgKku+ASERFZEoaPamjBAiAw8NFkUoVCe736fWxs+QGFiIjIHBg+qqFatYDPPpNe29gA9eppr/f3B7ZsAQYNkr82IiKiitiZuwCqnN69gVGjgO++A7y9pefbt6U5Hl26sMeDiIgsF3s+qrFly4C6daVLrx89Kt2ILiKCwYOIiCwbw0c1VrcusHy59HrePOCPP8xbDxERkT4YPqq54cOBPn2A/Hxg7Niy73zLm88REZGlYPio5hQK6W63rq7A//0fEB1dug1vPkdERJaE4aMGCAwEVq6UXs+bJ937RY03nyMiIkvD8FFDREUBb70lvR49Gjh+nDefIyIiy8TwUYMsXiydgpubCwwYAGzfzpvPERGR5WH4qEFsbYGNG4FmzaRhlRkz9Pscbz5HRERyYvioYTw8gB07gDp1gIsX9fsMbz5HRERyYviogRo3BjZvrvhiY7z5HBERmQPDRw3Vvbt0Y7my8OZzRERkLgwfNdiECcBrr0mvS975ljefIyIic+GN5WowhQL45BPpsusHDgB+fsDs2UCTJmXffE6lks5+ycjgTeqIiMg02PNRwzk4AFu3Slc0vX5durx65866AwWvhEpERHJg+LACdetKZ8DUqiXd12X4cOleMMXxSqhERCQXhg8rERoqXXZd3RPy/PPAw4fSOl4JlYiI5MTwYUX69pV6QJydgR9+APr1A7KypDkevBIqERHJheHDyvTqBfz4ozQEk5Agvdf3YmS8EioRERkDz3axQl27Avv2ScHj8GHg1i39PscroRIRkTGw58NKtW8vTT6tVw+4cAGwKyeGlrwSqkolfTYuTnrmXBAiIjIEw4cVCwuTrv/RoAFQWKi7TckrofJ0XCIiqiqGDyvXrJk0kTQkRHpf8vofxa+EytNxiYjIGBg+CCEhUg9I06bSEIqnJ/DBB0BiIpCaKgUPno5LRETGwvBBAKQejv37gVatgLt3gehoICUFsPnnN4Sn4xIRkbEwfJCGt7fU29G7N5CbC7z+OjBkCHD/vv6n2fJ0XCIiqojRw0dMTAzatWsHNzc31K9fHwMHDkRKSoqxd0Mm4ukJ7NoFfPSRdAbMli1A69ZSb4g+eDouERFVxOjhY//+/ZgwYQKOHDmCvXv3orCwED179kR2draxd0UmYmMDTJ0qXQOkYUPg8mVpvoe7e9mf4em4RESkL4UQuqYQGs+tW7dQv3597N+/H127dq2wvVKphIeHBzIzM+Fe3rcdyUKpBN54A9iwoew26tNxi58VM3my9hwRf39g+XJpPRER1TyGfH+bfM5HZmYmAMDT01Pn+ry8PCiVSq0HWQ53d+C774A1awAXF2mZTYnfGp6OS0REhjBpz4cQAgMGDMC9e/dwsIzTIKKjozFnzpxSy9nzYXn++AMYNgw4dUp6362bNCn1+eel64OoVNIFx8o6K0ahkIJKamrp64kQEVH1ZkjPh0nDx4QJE7Br1y4cOnQI/v7+Otvk5eUhLy9P816pVCIgIIDhw0Ll5gLTpgGffCK9d3SUhmWmT5fCSWRkxdtITAQiIkxaJhERycwihl3efPNN7NixA4mJiWUGDwBwdHSEu7u71oMsl5MT8PHH0iTSp58G8vKkS683bCidIaMP9em4nJRKRGSdjB4+hBCYOHEi4uPjkZCQgBD1dbupRgkPl66Kuncv8NRTwMOH0im6+vD15T1iiIismdHDx4QJE/Ddd99hw4YNcHNzw40bN3Djxg08fPjQ2LsiM1MogO7dpVNyd+8G2ratuH1AAHD7NielEhFZM6PP+VCoz7ssYc2aNRg9enSFn+epttWXEMDMmUBMjO71CgWwaRPw1luclEpEVNMY8v1tZ+ydm/iyIWTBFApg4ULgySeBceOAO3e01z37rPRa33vERERI80AOHpTmifj6ShcxYyghIqreTH6RMUOx56NmUKmkG9Xt2gX88IN0JgwgXbK9sLDiz2/YIJ1Jw4uVERFVDxZxtgtZN1tb4JlngCVLgHPngD17gK5d9QseAHDhAueFEBHVVOz5IFklJUl3zS12aRctCgXQoIH02pB5IRyeISIyL/Z8kMWKiCj/PjFCSHND9J0XAvC0XSKi6obhg2Q3aBCwdavUe6HLZ5/pt52MDN5LhoioOuKwC5lN8aGSevWA7GypV2TbNqCgoOLP//wzMHq0/sMzHJohIjIds55qS6QvW9vS93gZMAC4exdo1Ai4d6/sz6p7TfQdnrl7l2fOEBFZCg67kMXx9AS+/FLquSiLUgksWqTf9v73P/2HZni/GSIi02P4IIs0aBCwZUvpeSG1agG1a0vhY+9e/ba1fr3UC1KSetmUKVLI4MRVIiJ5cM4HWTRd8zSEAPbtA779VuqhKO83uG5d6V4yFZkzB4iOLr0tde/Lli2Phmc4d4SIqDRDvr8ZPqhaW78eGDWq7PUKRfnhRM3TU5oXUtY21BNX//c/zh0hItKF1/kgqzFypO7Tdp2dpUChb7QuK3gAjyauLljAuSNERMbAng+qEcoaCrl6FWjdWvsmd5Vlit4RDuEQUU3BYReiYtQXIgP07wmpLEPmjsTHcwiHiGoODrsQFaM+c0Z9zxi1gABpyCYjA/DyMs6+YmP1P7OGQzhEZK3Y80FWo7whjop6R5o3l+7OawyGXJlV3yEcfYZvOMRDRKbEYReiStA1DBIQIPVmDBggXfPj2rWqD920aQOcOFFxO32HcPQZvtF3iIcBhYgqi+GDqJIq0zuiDgOzZ0thwVhcXaX73eii7h1ZuhQYMqT8gAJIdRsjxKgxpBBRSQwfRCZS1d4RT0+gd2/pBnrGUFFAUc9zqWiIR58QY4peFA4XEdUcDB9EJlSV3pEtW/QLKQ4OQH6+yX6EUurVA27d0r2u5BwUY/WimGO4iGGHyHQM+v4WFiYzM1MAEJmZmeYuhahStm4Vwt9fCOkrWnoEBEjLi7dRKKRH8XbqZXPmaC+3hMfMmUJ4eZW9XqGQfs7//rf0z1X8Z9u69dHPX9U2ZR1vf3/t461vO323VVgoRGKiEBs2SM+FhaV/D4zVxpB2FTHWdoh0MeT7m+GDyAT0+Ue+vJBSWCit0/Xlq/4CrlfP/IFE18POrvz1Li5CODuX38bdXQgPj/Lb+PvrF3TUx1rOsGPMoGOsQGTMYKVvO0trY4k1WWLdlcXwQVRNlPcPQUW9I5s3VxxQ/P3LbwMIUbu2fqEiKMj8wcbQh5OTEM89V3HY8fCo+Dj4+AjxySdlH2tT9eoYIxBZai+SJQY5S2tjjv1VFsMHUQ1R0RBORQGl+BddVUJMQIAQP/9s/jBh6Q8bGyFsbctv4+oqRK1a5bepV0863hX1bvn6CrF6dfltFi6seDsNGki/B3L2IsnZhnXrv7+qYPggqkEq052ua45JVUNMdR0Kiogwfw014WFvL0TjxhWHK30ejo5Sr1R5bVxdpUdV2zg7C9Grl7TP8to5OEiPqrapVUsaNiyvjaen9CivjZeXFAjLm2el77ZcXcvv/VP/B6OqQzCGfH/zbBeiGsAYZ3GUdxpx8bNPyjubZ9Mm4K23yj6Tp/jpv1VtU7du2WfoFLdsGfDvf1fcztLUrg3cv2/uKsiaJCYCERGV/zzPdiGiSqnqRFn1+qoOBRlzuCgvr+pzY8zRq7Nsmbz70+cxaJD5a6jMo1s389dQmYePj7z727Chav9+cNiFiExKjqEgfdroE2L0bSfHBF992+gbmvQNRPXqGWc7lhiIWLfxHomJVft3geGDiMxOrlMD9Qkx+razlF4dffenb++P+pRkS+lFkrMN69Z/f3LO+WD4IKJqT85rJcjVq6NvO0OCjKX0IsndhnXrv7+qYPggIjIhS7vAlL5BxpJ6keRuY4k1WWLdVcGzXYiIrIyx7kkj931y5L4BoaXVZIl1VxZvLEdERESyMuT720ammoiIiIgAMHwQERGRzBg+iIiISFYMH0RERCQrhg8iIiKSFcMHERERyYrhg4iIiGTF8EFERESyYvggIiIiWdmZu4CS1BdcVSqVZq6EiIiI9KX+3tbnwukWFz4ePHgAAAgICDBzJURERGSoBw8ewMPDo9w2Fndvl6KiIly/fh1ubm5QKBR6f06pVCIgIADp6em8J4wMeLzlxeMtLx5vefF4y8tUx1sIgQcPHsDPzw82NuXP6rC4ng8bGxv4+/tX+vPu7u785ZURj7e8eLzlxeMtLx5veZnieFfU46HGCadEREQkK4YPIiIiklWNCR+Ojo6YPXs2HB0dzV2KVeDxlhePt7x4vOXF4y0vSzjeFjfhlIiIiGq2GtPzQURERNUDwwcRERHJiuGDiIiIZMXwQURERLJi+CAiIiJZ1YjwsWrVKoSEhMDJyQlPPvkkDh48aO6SaowDBw6gf//+8PPzg0KhwPbt27XWCyEQHR0NPz8/ODs7IyIiAmfPnjVPsdVcTEwM2rVrBzc3N9SvXx8DBw5ESkqKVhseb+P59NNP0apVK81VHjt27Ijdu3dr1vNYm1ZMTAwUCgWmTJmiWcZjbjzR0dFQKBRaDx8fH816cx/rah8+Nm3ahClTpmDmzJk4efIkunTpgj59+uDKlSvmLq1GyM7ORlhYGFasWKFz/eLFi7F06VKsWLECx44dg4+PD3r06KG5QSDpb//+/ZgwYQKOHDmCvXv3orCwED179kR2dramDY+38fj7++ODDz7Ab7/9ht9++w3PPPMMBgwYoPkHmMfadI4dO4bPP/8crVq10lrOY25cLVq0QEZGhuZx5swZzTqzH2tRzbVv3168/vrrWsuaNWsmZsyYYaaKai4AYtu2bZr3RUVFwsfHR3zwwQeaZbm5ucLDw0OsXr3aDBXWLDdv3hQAxP79+4UQPN5yqFOnjvjyyy95rE3owYMHonHjxmLv3r0iPDxcTJ48WQjB329jmz17tggLC9O5zhKOdbXu+cjPz8fx48fRs2dPreU9e/bE4cOHzVSV9UhNTcWNGze0jr+joyPCw8N5/I0gMzMTAODp6QmAx9uUVCoVNm7ciOzsbHTs2JHH2oQmTJiAZ599Ft27d9dazmNufBcuXICfnx9CQkIwbNgwXLp0CYBlHGuLu6utIW7fvg2VSgVvb2+t5d7e3rhx44aZqrIe6mOs6/hfvnzZHCXVGEIIvPXWW3j66afRsmVLADzepnDmzBl07NgRubm5qFWrFrZt24bmzZtr/gHmsTaujRs34sSJEzh27Fipdfz9Nq4OHTrg22+/RZMmTfD3339j/vz56NSpE86ePWsRx7pahw81hUKh9V4IUWoZmQ6Pv/FNnDgRp0+fxqFDh0qt4/E2nqZNmyI5ORn379/H1q1bERUVhf3792vW81gbT3p6OiZPnoyffvoJTk5OZbbjMTeOPn36aF6HhoaiY8eOeOyxx/DNN9/gqaeeAmDeY12th13q1q0LW1vbUr0cN2/eLJXoyPjUM6d5/I3rzTffxI4dO5CYmAh/f3/Nch5v43NwcECjRo3Qtm1bxMTEICwsDMuXL+exNoHjx4/j5s2bePLJJ2FnZwc7Ozvs378fH3/8Mezs7DTHlcfcNFxdXREaGooLFy5YxO93tQ4fDg4OePLJJ7F3716t5Xv37kWnTp3MVJX1CAkJgY+Pj9bxz8/Px/79+3n8K0EIgYkTJyI+Ph4JCQkICQnRWs/jbXpCCOTl5fFYm0C3bt1w5swZJCcnax5t27bFyJEjkZycjIYNG/KYm1BeXh7Onz8PX19fy/j9lmVaqwlt3LhR2Nvbi6+++kqcO3dOTJkyRbi6uoq0tDRzl1YjPHjwQJw8eVKcPHlSABBLly4VJ0+eFJcvXxZCCPHBBx8IDw8PER8fL86cOSOGDx8ufH19hVKpNHPl1c8bb7whPDw8RFJSksjIyNA8cnJyNG14vI3n3XffFQcOHBCpqani9OnT4j//+Y+wsbERP/30kxCCx1oOxc92EYLH3JimTp0qkpKSxKVLl8SRI0dEv379hJubm+a70dzHutqHDyGEWLlypQgKChIODg6iTZs2mlMTqeoSExMFgFKPqKgoIYR0ytbs2bOFj4+PcHR0FF27dhVnzpwxb9HVlK7jDECsWbNG04bH23jGjBmj+XejXr16olu3bprgIQSPtRxKhg8ec+MZOnSo8PX1Ffb29sLPz08MGjRInD17VrPe3MdaIYQQ8vSxEBEREVXzOR9ERERU/TB8EBERkawYPoiIiEhWDB9EREQkK4YPIiIikhXDBxEREcmK4YOIiIhkxfBBREREsmL4ICIiIlkxfBAREZGsGD6IiIhIVv8PXsxCDx9JkZEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history_vgg16.history['accuracy']\n",
    "val_acc = history_vgg16.history['val_accuracy']\n",
    "loss = history_vgg16.history['loss']\n",
    "val_loss = history_vgg16.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
      "Predicted class: Glass\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Check a photo to classify\n",
    "img_path = 'trash_classifier/test/Plastic/Plastic_1214.jpg'\n",
    "img = keras.utils.load_img(\n",
    "    str(curr_dir / img_path),\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "img_array = keras.applications.vgg16.preprocess_input(img_array)\n",
    "\n",
    "features = base_model.predict(img_array)\n",
    "\n",
    "\n",
    "# Get the predicted class\n",
    "predictions = model_vgg16.predict(features)\n",
    "\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# Print the predicted class\n",
    "predicted_class_name = CATEGORIES[predicted_class]\n",
    "print(f\"Predicted class: {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_45\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_45\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_46      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stack (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Stack</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ stack[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ vgg16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_61          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_112[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,313</span> │ dropout_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_46      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_46[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stack (\u001b[38;5;33mStack\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ stack[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │ \u001b[38;5;34m14,714,688\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ vgg16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_112 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m6,422,784\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_61          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_112[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_113 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │      \u001b[38;5;34m2,313\u001b[0m │ dropout_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,139,785</span> (80.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,139,785\u001b[0m (80.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,425,097</span> (24.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,425,097\u001b[0m (24.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  1/282\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:54\u001b[0m 8s/step - accuracy: 0.1875 - loss: 15.6787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 50\u001b[0m\n\u001b[1;32m     41\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     42\u001b[0m   keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     43\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcurr_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrash_classifier\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16.keras\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m   )\n\u001b[1;32m     47\u001b[0m ]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 6. Train the model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m history_vgg16 \u001b[38;5;241m=\u001b[39m model_vgg16\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     51\u001b[0m   train_dataset,\n\u001b[1;32m     52\u001b[0m   epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     53\u001b[0m   validation_data\u001b[38;5;241m=\u001b[39mvalidation_dataset,\n\u001b[1;32m     54\u001b[0m   callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 7. Evaluate the model\u001b[39;00m\n\u001b[1;32m     58\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model_vgg16\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "base_model: keras.applications.VGG16 = keras.applications.VGG16(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "\n",
    "# 1. Data augmentation constant\n",
    "data_augmentation = keras.Sequential([\n",
    "  keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  keras.layers.RandomRotation(0.1),\n",
    "  keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# 2. Freeze the base model to fine-tune only the top layers\n",
    "base_model.trainable = False  # Freeze convolutional base\n",
    "\n",
    "# 3. Create the model\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(9, activation='softmax')(x)\n",
    "model_vgg16 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_vgg16.summary()\n",
    "# 4. Compile the model\n",
    "model_vgg16.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 5. Create callback to save the best model\n",
    "callbacks = [\n",
    "  keras.callbacks.ModelCheckpoint(\n",
    "    filepath=curr_dir / 'trash_classifier' / 'vgg16.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "  )\n",
    "]\n",
    "\n",
    "# 6. Train the model\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "  train_dataset,\n",
    "  epochs=10,\n",
    "  validation_data=validation_dataset,\n",
    "  callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "loss, accuracy = model_vgg16.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
